

<section xml:id="Ch3Sec5KernelRange">
  <title>Kernel and range of a linear map</title>
  <definition>
    <statement>
      <p>
        Let <m>T : V \rightarrow W</m> be a linear map between vector spaces <m>V</m> and <m>W</m>.
        The <term>kernel</term> of <m>T</m>, written <m>\Ker(T)</m>,
        is the set of all vectors <m>\ve{v} \in V</m> such that are mapped to <m>\ve{0}_W</m> by <m>T</m>.
        That is,
        <me>
          \Ker(T) := \{ \ve{v} \in V : T(\ve{v}) = \ve{0}_W \}
        </me>.
      </p>

      <p>
        The <term>image</term> of <m>T</m>, written <m>\Im(T)</m>,
        is the set of all vectors <m>\ve{w} \in W</m> such that
        <m>\ve{w} = T(\ve{v})</m> for some <m>\ve{v} \in V</m>.
        That is,
        <me>
          \Im(T) := \{ \ve{w} \in W : \ve{w} = T(\ve{v}) \mbox{ for some \(\ve{v} \in V\)}  \}
        </me>
      </p>
    </statement>
  </definition>

  <p>
    See <xref ref="ker_fig"/> and <xref ref="im_fig"/>
    for a schematic representation.
  </p>

  <assemblage>
    <p>
      Sometimes, to be absolutely clear, I will put a subscript on the zero vector to indicate which vector space it belongs to, eg.
      <m>\ve{0}_W</m> refers to the zero vector in <m>W</m>,
      while <m>\ve{0}_V</m> refers to the zero vector in <m>V</m>.
    </p>
  </assemblage>

  <assemblage>
    <p>
      Another name for the kernel of <m>T</m> is the
      <em>nullspace</em> of <m>T</m>,
      and another name for the image of <m>T</m> is the
      <em>range</em> of <m>T</m>.
    </p>
  </assemblage>

  <figure xml:id = "ker_fig">

    <image>

<latex-image>
          <![CDATA[\begin{tikzpicture}[scale=1.1]
 \draw (0,0) circle (1);
 \draw (0,0) circle (0.3);
 \draw (3,0) circle (1);
 \node at (0, -1.2) {\(V\)};
 \node at (3, -1.2) {\(W\)};
 \draw (0.083*0.6, 0.493*0.6) -- (3,0);
 \draw (0.083*0.6, -0.493*0.6) -- (3,0);
 \fill[fill=black] (3,0) circle (0.05);
 \node at (3.4, 0) {\(\ve{0}_W\)};
 \node at (0, -0.5) {\(\Ker(T)\)};\end{tikzpicture}]]>
</latex-image>
    </image>
    <caption><m>\Ker(T)</m> </caption>
  </figure>

<figure xml:id = "im_fig">
    <image>

<latex-image>
          <![CDATA[\begin{tikzpicture}[scale=1.1]
 \draw (0,0) circle (1);
 \draw (3,0) circle (0.3);
 \draw (3,0) circle (1);
 \node at (0, -1.2) {\(V\)};
 \node at (3, -1.2) {\(W\)};
 \draw (0.15, 0.987) -- (3.03,0.3);
 \draw (0.15, -0.987) -- (3.03,-0.3);
 \node at (3, -0.5) {\(\Im(T)\)};\end{tikzpicture}]]>
</latex-image>
    </image>

   <caption > <m>\Im(T)</m></caption>
  </figure>

  <lemma xml:id="ker-im-subspace">
    <statement>
      <p>
        Let <m>T : V \rightarrow W</m> be a linear map.
        Then:

        <ol>
          <li>
            
            <p>
              <m>\Ker(T)</m> is a subspace of <m>V</m>
            </p>
          </li>

          <li>
            
            <p>
              <m>\Im(T)</m> is a subspace of <m>W</m>
            </p>
          </li>
        </ol>
      </p>
    </statement>
  </lemma>

  <proof>
    <p>
      (i) We must check the three requirements for being a subspace.

      <ol>
        <li>
       
          <p>
            <m>\Ker(T)</m> is closed under addition.

            <p>
              Suppose <m>\ve{v}</m> and <m>\ve{v}'</m> are in <m>\Ker(T)</m>. In other words, <m>T(\ve{v}) = \ve{0}</m> and <m>T(\ve{v}') = \ve{0}</m>. We need to show that <m>\ve{v} + \ve{v}'</m> is in <m>\Ker(T)</m>, in other words, that <m>T(\ve{v} + \ve{v}') = \ve{0}</m>. Indeed,
              <me>
                T(\ve{v} + \ve{v}') = T(\ve{v}) + T(\ve{v}') = \ve{0} + \ve{0} = \ve{0}
              </me>.
            </p>

          </p>
        </li>

        <li>
        
          <p>
            <m>\ve{0}_V \in \Ker(T)</m>.

            <p>
              To show that <m>\ve{0}_V</m> is in <m>\Ker(T)</m>, we need to show that <m>T(\ve{0}_V) = \ve{0}_W</m>. Indeed, this is true since <m>T</m> is a linear map, by <xref ref="lin_map_zero_to_zero">Lemma</xref>.
            </p>

          </p>
        </li>

        <li>
          
          <p>
            <m>\Ker(T)</m> is closed under scalar multiplication.

            <p>
              Suppose <m>\ve{v} \in \Ker(T)</m> and <m>k \in \mathbb{R}</m> is a scalar. We need to show that <m>k \ve{v} \in \Ker(T)</m>, that is, we need to show that <m>T(k \ve{v}) = \ve{0}</m>. Indeed,
              <me>
                T(k \ve{v}) = k T(\ve{v}) = k \ve{0} = \ve{0}
              </me>.
            </p>

          </p>
        </li>
      </ol>
    </p>

    <p>
      (ii) Again, we must check the three requirements for being a subspace.

      <ol>
        <li>
          
          <p>
            <m>\Im(T)</m> is closed under addition.

            <p>
              Suppose <m>\ve{w}</m> and <m>\ve{w}'</m> are in <m>\Im(T)</m>. In other words, there exist vectors <m>\ve{v}</m> and <m>\ve{v}'</m> in <m>V</m> such that <m>T(\ve{v}) = \ve{w}</m> and <m>T(\ve{v}') = \ve{w}'</m>. We need to show that <m>\ve{w} + \ve{w}'</m> is also in <m>\Im(T)</m>, in other words, that there exists a vector <m>\ve{u}</m> in <m>V</m> such that <m>T(\ve{u}) = \ve{w} + \ve{w}'</m>. Indeed, set <m>\ve{u} := \ve{v} + \ve{v}'</m>. Then,
              <me>
                T(\ve{u}) = T(\ve{v} + \ve{v}') = T(\ve{v}) + T(\ve{v}') = \ve{w} + \ve{w}'
              </me>.
            </p>

          </p>
        </li>

        <li>
          
          <p>
            <m>\ve{0}_W \in \Im(T)</m>.

            <p>
              To show that <m>\ve{0}_W \in \Im(T)</m>, we need to show that there exists <m>\ve{v} \in V</m> such that <m>T(\ve{v}) = \ve{0}_W</m>. Indeed, choose <m>\ve{v} = \ve{0}_V</m>. Then <m>T(\ve{v}) = T(\ve{0}_V) = \ve{0}_W</m> by <xref ref="lin_map_zero_to_zero">Lemma</xref>.
            </p>

          </p>
        </li>

        <li>
          <title>c.</title>
          <p>
            <m>\Im(T)</m> is closed under scalar multiplication.

            <p>
              Suppose <m>\ve{w} \in \Im(T)</m> and <m>k</m> is a scalar. We need to show that <m>k \ve{w} \in \Im(T)</m>. The fact that <m>\ve{w}</m> is in <m>\Im(T)</m> means that there exists a <m>\ve{v}</m> in <m>V</m> such that <m>T(\ve{v}) = \ve{w}</m>. We need to show that there exists a <m>\ve{u} \in V</m> such that <m>T(\ve{u}) = k \ve{w}</m>. Indeed, set <m>\ve{u} := k \ve{v}</m>. Then
              <me>
                T(\ve{u}) = T(k \ve{v}) = k T(\ve{v}) = k \ve{w}
              </me>.
            </p>

          </p>
        </li>
      </ol>
    </p>
  </proof>

  <p>
    Now that we know that the kernel and image of a linear map are subspaces,
    and hence vector spaces in their own right,
    we can make the following definition.
  </p>

  <definition>
    <statement>
      <p>
        Let <m>T : V \rightarrow W</m> be a linear map from a finite-dimensional vector space <m>V</m> to a vector space <m>W</m>.
        The <term>nullity</term> of <m>T</m> is the dimension of <m>\Ker(T)</m>,
        and the <term>rank</term> of <m>T</m> is the dimension of <m>\Im(T)</m>:
        <md>
          <mrow>\Nullity(T) \amp := \Dim (\Ker(T))</mrow>
          <mrow>\Rank(T) \amp = \Dim (\Im(T))</mrow>
        </md>
      </p>
    </statement>
  </definition>

  <assemblage>
    <p>
      The <sq>dimension of <m>\Ker(T)</m></sq> makes sense because <m>\Ker(T)</m> is a subspace of a finite-dimensional vector space <m>V</m>,
      and hence is finite-dimensional by <xref ref="dim-of-subspace-prop">Proposition</xref>.
      We do not yet know that <m>\Im(T)</m> is finite-dimensional,
      but this will follow from the Rank-Nullity Theorem
      (<xref ref="rank-nullity-theorem">Theorem</xref>).
    </p>
  </assemblage>

  <example xml:id="cross-product-example">
    <statement>
      <p>
        Let <m>\ve{a} \in \mathbb{R}^3</m> be a fixed nonzero vector.
        Consider the <sq>cross product with <m>\ve{a}</m></sq> linear map from <xref ref="cross_prod_as_linear_map">Example</xref>,
        <md>
          <mrow>C : \mathbb{R}^3 \amp  \rightarrow \mathbb{R}^3</mrow>
          <mrow>\ve{v} \amp \mapsto \ve{a} \times \ve{v}</mrow>
        </md>
      </p>

      <p>
        Determine the kernel, image, nullity and rank of <m>C</m>.
      </p>
    </statement>
    <solution>
      <p>
        The kernel of <m>C</m> is the subspace of
        <m>\mathbb{R}^3</m> consisting of all vectors
        <m>\ve{v} \in V</m> such that <m>\ve{a} \times \ve{v} = \ve{0}</m>.
        From the geometric formula for the cross-product,
        <me>
          |\ve{a} \times \ve{v}| = |\ve{a}| |\ve{v}| \sin \theta
        </me>
        where <m>\theta</m> is the angle from <m>\ve{a}</m> to <m>\ve{\theta}</m>,
        we see that
        <me>
          \ve{a} \times \ve{v} = \ve{0}  \Leftrightarrow  \mbox{\(\ve{v}=\ve{0}\) or \(\theta = 0\) or \(\theta= \pi\)} 
        </me>.
      </p>

      <p>
        In other words,
        <m>\ve{v}</m> must be a scalar multiple of <m>\ve{a}</m>.
        So,
        <me>
          \Ker(C) = \{ k \ve{a}, k \in \mathbb{R} \}
        </me>.
      </p>

      <p>
        I claim that the <em>image</em>
        of <m>C</m> is the subspace of <em>all</em>
        vectors perpendicular to <m>\ve{a}</m>, i.e.
        <men xml:id="image-of-C">
          \Im(C) := \{ \ve{u} \in \mathbb{R}^3 : \ve{u} \dotp \ve{a} = 0 \}
        </men>.
      </p>

      <p>
        If you believe me, then the picture is as follows:
      </p>

      <image>

<latex-image>
          <![CDATA[\begin{tikzpicture}\draw (0,0) -- (1,2) -- (3,2) -- (2,0) -- (0,0);
  \draw (1.5, 1) -- (1.5,3.5) node[right] {\(\Ker{C}\)};
  \draw (1.5, -0.1) -- (1.5, -2);
  \node at (3.3, 1) {\(\Im(C)\)};  
  \draw[very thick, red, ->] (1.5,1) -- (1.5, 2.5) node[right] {\(\ve{a}\)};\end{tikzpicture}]]>
</latex-image>
      </image>

      <p>
        Let me prove equation <xref ref="image-of-C" />.
        By definition, the image of <m>C</m> is the subspace of
        <m>\mathbb{R}^3</m> consisting of all vectors <m>\ve{w}</m> of the form
        <m>\ve{w} = \ve{a} \times \ve{v}</m> for some <m>\ve{v} \in \mathbb{R}^3</m>.
        This implies that <m>\ve{w}</m> is perpendicular to <m>\ve{a}</m>.
        This was the <sq>easy</sq> part.
        The <sq>harder</sq> part is to show the converse.
        That is, we need to show that if <m>\ve{u}</m> is perpendicular to <m>\ve{a}</m>,
        then <m>\ve{u}</m> is in the image of <m>C</m>,
        i.e. there exists a vector <m>\ve{v}</m> such that <m>C(\ve{v}) = \ve{u}</m>.
      </p>

      <p>
        Indeed, we can choose <m>\ve{v}</m> to be the vector obtained by rotating <m>\ve{u}</m> by 90 degrees clockwise in the plane <m>I</m>,
        and scaling it appropriately:
      </p>

      <image>

<latex-image>
          <![CDATA[\begin{tikzpicture}\draw (0,0) -- (1,2) -- (3,2) -- (2,0) -- (0,0);
\draw[very thick, red, ->] (1.5,1) -- (1.5, 2.5) node[right] {\(\ve{a}\)};
\draw[very thick, blue, ->] (1.5,1) -- (1.75, 1.5) node[right, xshift=-6pt, yshift=3pt] {\(\ve{u}\)};
\draw[very thick, green, ->] (1.5,1) -- (2, 1) node[xshift=-4pt, right] {\(\ve{v}\)};\end{tikzpicture}]]>
</latex-image>
      </image>

      <p>
        In terms of a formula, we have
        <me>
          \ve{v} = \frac{|\ve{u}|}{|\ve{a}|} \ve{u} \times \ve{a} 
        </me>.
      </p>

      <p>
        Note that this is not the <em>only</em>
        vector <m>\ve{v}</m> such that <m>C(\ve{v}) = \ve{u}</m>.
        Indeed, if we add to <m>\ve{v}</m> any vector that lies on the line through <m>\ve{a}</m>,
        the resulting vector
        <me>
          \tilde{\ve{v}} = \ve{v} + k \ve{a}
        </me>
      </p>

      <p>
        <em>also</em> satisfies <m>C(\tilde{\ve{v}}) = \ve{u}</m>, since
        <me>
          C(\tilde{\ve{v}}) = C(\ve{v} + k \ve{a}) = C(\ve{v}) + C(k \ve{a}) = \ve{u} + \ve{0} = \ve{u}
        </me>.
      </p>
    </solution>
  </example>

  <example>
    <statement>
      <p>
        Determine the kernel, image, nullity and rank of the linear map
        <md>
          <mrow>I : \Trig_2 \amp  \rightarrow \mathbb{R}</mrow>
          <mrow>f \amp  \mapsto \int_0^\pi f(x) dx </mrow>
        </md>.
      </p>
    </statement>
    <solution>
      <p>
        The kernel of <m>I</m> consists of all degree 2 trigonometric polynomials
        <me>
          f(x) = a_0 + a_1 \cos x + b_1 \sin x + a_2 \cos 2x + b_2 \sin 2x
        </me>
        such that
        <me>
          \int_0^\pi (a_0 + a_1 \cos x + b_1 \sin x + a_2 \cos 2x + b_2 \sin 2x) \, dx = 0
        </me>.
      </p>

      <p>
        Performing the integrals, this becomes the equation
        <me>
          \pi a_0 + 2 b_1 = 0
        </me>
        with no constraints on the other constants <m>a_1, a_2, b_2</m>.
        In other words,
        <me>
          \Ker(I) = \left\{ \text{ all trigonometric polynomials of the form  } \\ (a_0(1 - \frac{\pi}{2} \sin x) + a_1 \cos x + a_2 \cos{2x} + b_2 \sin{2x}), \text{ where } (a_0, a_1, a_2, b_2 \in \mathbb{R}). \right\}
        </me>
      </p>

      <p>
        Hence <m>\Nullity(I) = \Dim (\Ker(I)) = 4</m>.
      </p>

      <p>
        The image of <m>I</m> consists of all real numbers
        <m>p \in \mathbb{R}</m> such that there exists a
        <m>f \in \Trig_2</m> such that <m>I(f) = p</m>.
        I claim that
        <me>
          \Im(I) = \mathbb{R}
        </me>.
      </p>

      <p>
        Indeed, given <m>p \in \mathbb{R}</m>,
        we may choose <m>f(x) = \frac{p}{2} \sin{x}</m>, since
        <me>
          I(f) = \frac{p}{2} \int_0^\pi \sin{x} \, dx  = p
        </me>.
      </p>

      <p>
        Hence <m>\Im(I) = \mathbb{R}</m>, and <m>\Rank(I) = 1</m>.
      </p>

      <p>
        Note that the choice of <m>f(x) = \frac{p}{2} \sin(x)</m> satisfying <m>I(f) = p</m> is not unique.
        We could set <m>\tilde{f} = f + g</m> where
        <m>g \in \Ker(I)</m> and we would still have <m>I(\tilde{f})=p</m>:
        <me>
          I(\tilde{f}) = I(f + g) = I(f) + I(g) =  p + 0 = p
        </me>.
      </p>
    </solution>
  </example>

  <example>
    <statement>
      <p>
        Consider the function
        <md>
          <mrow>T : \Poly_2 \amp  \rightarrow \mathbb{R}^2</mrow>
          <mrow>p \amp  \mapsto (p(1), p'(1))</mrow>
        </md>.
      </p>

      <p>
        Show that <m>T</m> is a linear map,
        and determine its kernel, image, rank and nullity.
      </p>
    </statement>
    <solution>
      <p>
        We first show that <m>T</m> is a linear map.
        Let <m>p,q \in \Poly_2</m>.
        Then
        <md>
          <mrow>T(p + q) \amp = ( (p+q)(1), \, (p+q)'(1) )  \amp \amp  \mbox{(Defn of \(T\))}</mrow>
          <mrow>\amp = (p(1) + q(1), \, (p+q)'(1) ) \amp \amp  \mbox{(Defn of the function \(p+q\))}</mrow>
          <mrow>\amp = (p(1) + q(1), \, (p'+q')(1) ) \amp \amp  \mbox{(\((p+q)' = p'+q'\))}</mrow>
          <mrow>\amp = (p(1) + q(1), \, p'(1) + q'(1)) \amp \amp  \mbox{(Defn of the function \(p' + q'\))}</mrow>
          <mrow>\amp = (p(1), \, p'(1)) + (q(1), \, q'(1)) \amp \amp  \mbox{(Defn of addition in \(\mathbb{R}^2\))}</mrow>
          <mrow>\amp = T(p) + T(q)</mrow>
        </md>.
      </p>

      <p>
        The proof of <m>T(kp) = kT(p)</m> is similar.
      </p>

      <p>
        The kernel of <m>T</m> is the set of all polynomials
        <me>
          p(x) = a_0 + a_1 x + a_2 x^2
        </me>
        such that <m>T(p) = (0,0)</m>.
        This translates into the equation
        <me>
          (a_0 + a_1 + a_2, \, a_1 + 2 a_2) = (0,0)
        </me>.
      </p>

      <p>
        This in turn translates into two equations:
        <md>
        <mrow>  a_0 + a_1 + a_2 \amp = 0 </mrow>
        <mrow> a_0 + a_1 + a_2 \amp = 0 </mrow>
        <mrow> a_1 + 2a_2 \amp = 0 </mrow>
        </md>
        whose solution is <m>a_2 = t</m>,
        <m>a_1 = - 2t</m>, <m>a_0 = -t</m>,
        where <m>t \in \mathbb{R}</m>.
        Hence
        <me>
          \Ker(T) =  \left\{ \mbox{ all polynomials of the form \( -t -2t x + t x^2\)  where  \(t \in \mathbb{R}\) }  \right\}
        </me>.
      </p>

      <p>
        Hence <m>\Nullity(T) = 1</m>.
      </p>

      <p>
        The image of <m>T</m> is the set of all
        <m>(v,w) \in \mathbb{R}^2</m> such that there exists a polynomial
        <m>p = a_0 + a_1 x + a_2 x^2</m> in <m>\Poly_2</m> such that <m>T(p) = (v,w)</m>.
        So, <m>(v,w)</m> is in the image of <m>T</m> if and only if we can find a polynomial <m>p = a_0 + a_1x + a_2 x^2</m> such that
        <me>
          (a_0 + a_1 + a_2, a_1 + 2a_2) = (v,w)
        </me>.
      </p>

      <p>
        In other words,
        <m>(v,w)</m> is in the image of <m>T</m> if and only if the equations
        <md>
        <mrow> a_0 + a_1 + a_2 \amp = v </mrow>
        <mrow>a_1 + 2a_2 \amp = w</mrow>
        </md>
        have a solution for some <m>a_0, a_1, a_2</m>.
        But these equations <em>always</em> have a solution,
        for <em>all</em> <m>(v,w) \in \mathbb{R}^2</m> is.
        For instance, one solution is
        <me>
          a_2 = 0 ,  \, a_1 = w, \, a_0 = v - w
        </me>
        which corresponds to the polynomial
        <men xml:id="one-soln-for-preimage">
          p(x) = v-w + wx
        </men>.
      </p>

      <p>
        Note that indeed <m>T(p) = (v,w)</m>.
        Hence,
        <me>
          \Im(T) = \{\mbox{all }  (v,w) \in \mathbb{R}^2 \} = \mathbb{R}^2
        </me>.
      </p>

      <p>
        Hence <m>\Rank (T) = \Dim (\Im(T)) = 2</m>.
      </p>

      <p>
        Note that the choice of the polynomial
        <m>p(x) = v-w + w x</m> from <xref ref="one-soln-for-preimage" /> which satisfies <m>T(p) = (v,w)</m> is not the
        <em>only</em> possible choice.
        Indeed, any polynomial of the form <m>\tilde{p} = p + q</m> where
        <m>q \in \Ker(T)</m> will also satisfy <m>T(\tilde{p}) = (v,w)</m>, since
        <me>
          T(\tilde{p}) = T(p + q) = T(p) + T(q) = (v,w) + (0,0) = (v,w)
        </me>.
      </p>
    </solution>
  </example>

  <theorem xml:id="rank-nullity-theorem">
    <title>Rank-nullity theorem</title>
    <statement>
      <p>
        Let <m>T : V \rightarrow W</m> be a linear map from a finite-dimensional vector space <m>V</m> to a vector space <m>W</m>.
        Then
        <me>
          \Nullity(T) + \Rank(T) = \Dim(V)
        </me>.
      </p>
    </statement>
  </theorem>

  <proof>
    <p>
      Let <m>\basis{B} = \bopen \ve{e}_1, \ldots, \ve{e}_k \bclose</m> be a basis for <m>\Ker(T)</m>.
      Since <m>\basis{B}</m> is a list of linearly independent vectors in <m>V</m>,
      we can extend it to a basis <m>\basis{C} = \bopen \ve{e}_1, \ldots, \ve{e}_k, \ve{f}_1, \ldots, \ve{f}_p \bclose</m> for <m>V</m>,
      by <xref ref="first_corollary_please">Corollary</xref>.
      I claim that
      <me>
        \basis{D} := \bopen T(\ve{f}_1), \ldots, T(\ve{f}_p) \bclose
      </me>
      is a basis for <m>\Im(T)</m>.
      If I can prove that, then we are done, since then we have
      <md>
        <mrow>\Nullity(T) + \Rank(T) \amp = k + p</mrow>
        <mrow>\amp = \Dim(V)</mrow>
      </md>.
    </p>

    <p>
      Let us prove that <m>\basis{D}</m> is a basis for <m>\Im(T)</m>.
    </p>

    <p>
      <em><m>\basis{D}</m> is linearly independent</em>.
      Suppose
      <me>
        b_1 T(\ve{f}_1) + \cdots + b_p T(\ve{f}_p) = \ve{0}_W
      </me>.
    </p>

    <p>
      We recognize the left hand side as <m>T(b_1 \ve{f}_1 + \cdots + b_p \ve{f}_p)</m>.
      Hence
      <me>
        b_1 \ve{f}_1 + \cdots + b_p \ve{f}_p \in \Ker(T)
      </me>
      which means we can write it as a linear combination of the vectors in <m>\basis{B}</m>,
      <me>
        b_1 \ve{f}_1 + \cdots + b_p \ve{f}_p = a_1 \ve{e}_1 + \cdots + a_k \ve{e}_k
      </me>.
    </p>

    <p>
      Bringing all terms onto one side, this becomes the equation
      <me>
        -a_1 \ve{e}_1 - \cdots -a_k \ve{e}_k + b_1 \ve{f}_1 + \cdots + b_p \ve{f}_p = \ve{0}_V
      </me>.
    </p>

    <p>
      We recognize the left hand side as a linear combination of the <m>\basis{C}</m> basis vectors.
      Since they are are linearly independent,
      all the scalars must be zero.
      In particular, <m>b_1 = \cdots = b_p = 0</m>,
      which is what we wanted to prove.
    </p>

    <p>
      <em><m>\basis{D}</m> spans <m>W</m></em>.
      Suppose <m>\ve{w} \in \Im(T)</m>.
      We need to show that <m>\ve{w}</m> is a linear combination of the vectors from <m>\basis{D}</m>.
      Since <m>\ve{w}</m> is in the image of <m>T</m>,
      there exists <m>\ve{v} \in V</m> such that <m>T(\ve{v}) = \ve{w}</m>.
      Since <m>\basis{C}</m> is a basis for <m>V</m>, we can write
      <me>
        \ve{v} = a_1 \ve{e}_1 + \cdots + a_k \ve{e}_k + b_1 \ve{f}_1 + \cdots + b_p \ve{f}_p
      </me>
      for some scalars <m>a_1, \ldots,
      a_k, b_1, \ldots, b_p</m>.
      Then
      <md>
        <mrow>\ve{w} \amp =   T(\ve{v})</mrow>
        <mrow>\amp = T(a_1 \ve{e}_1 + \cdots + a_k \ve{e}_k + b_1 \ve{f}_1 + \cdots + b_p \ve{f}_p)</mrow>
        <mrow>\amp = a_1 T(\ve{e}_1) + \cdots + a_k T(\ve{e}_k) + b_1 T(\ve{f}_1) + \cdots + b_p T(\ve{f}_p)</mrow>
        <mrow>\amp = b_1 T(\ve{f}_1) + \cdots + b_p T(\ve{f}_p) \amp \amp  \mbox{(\(\ve{e}_i \in \Ker(T)\))}</mrow>
      </md>
      so that <m>\ve{w}</m> is indeed a linear combination of the vectors from <m>\basis{D}</m>.
    </p>
  </proof>

  <exercises>
    <exercise>
    <statement>
      <p>
        Verify the Rank-Nullity theorem for the following linear maps.
        That is, for each map <m>T</m>, (a) determine <m>\Ker(T)</m> and <m>\Im(T)</m> explicitly, (b) determine the dimension of <m>\Ker(T)</m> and <m>\Im(T)</m>, (c) check that these numbers satisfy the Rank-Nullity theorem.

        <ol>
          <li>
            <p>
              The identity map <m>\id_V : V \rightarrow V</m> on a finite-dimensional vector space <m>V</m>.
            </p>
          </li>

          <li>
            <p>
              The zero map
              <md>
                <mrow>Z : V \amp  \rightarrow V</mrow>
                <mrow>\ve{v} \amp  \mapsto \ve{0}</mrow>
              </md>
              on a finite-dimensional vector space <m>V</m>.
            </p>
          </li>

          <li>
            <p>
              The map
              <md>
                <mrow>T : \Poly_3 \amp  \rightarrow \Col_3</mrow>
                <mrow>p \amp  \mapsto \begin{bmatrix} p(1) \\ p(2) \\ p(3)\end{bmatrix}</mrow>
              </md>
            </p>
          </li>

          <li>
            <p>
              The map
              <md>
                <mrow>S : \Trig_2 \amp  \rightarrow \Col_2</mrow>
                <mrow>f \amp  \mapsto \begin{bmatrix} \displaystyle \int_0^\pi f(x) \cos x dx \\
                \displaystyle \int_0^\pi f(x) \sin x dx \end{bmatrix} </mrow>
              </md>
            </p>
          </li>
        </ol>
      </p>
    </statement>
    <solution> 

      <p>

        <ol>
<li>
<p>
<m>\id_V</m> sends only a single vector to <m>0</m>, namely the vector <m>\ve 0_v</m>. Thus <m>\Ker(\id_v) = \{\ve 0_v\}</m> and hence <m>\Nullity(\id_v) = 0</m>. <m>\Im(\id_V) = V</m>  and so <m>\Rank(\id_V) = \Dim(V) </m>. The equation
<me>
\Dim V + 0 = \Dim V .
</me>
verifies the Rank-Nullity Theorem for this example.
</p>
</li>


<li>
<p>
The zero map spends every element in <m>V </m> to <m> \ve 0 </m>. Hence <m>\Ker(Z) = V </m> and so <m> \Nullity(Z) = \Dim V </m>. For the same reason <m>\Im(Z) = \{0\}</m> and thus <m>\Rank(Z) = 0 </m>. The equation
<me>
\Dim V + 0 = \Dim V .
</me>
verifies the Rank-Nullity Theorem for this example.
</p>
</li>


<li>
<p>
  <m> \ve p(x) \in \Ker(T) </m> if and only if 
  <me>
p(1) = p(2) = p(3) = 0.
</me>
But any degree 3 polynomial with <m>1, 2</m> and <m> 3</m> as roots must be of the form
<me>
a(x-1)(x-2)(x-3)
</me>
where <m> a \in \mathbb R </m>. Conversely, any element of this form is in <m> \Ker T </m>. Hence
<me>
\Ker(T) = \{a(x-1)(x-2)(x-3) \in \Poly_3 \, : \, a \in \mathbb R\} 
</me>
and thus <m> \Nullity(T)  = 1 </m>.
</p>

<p>
I claim that <m>\Im(T) = \Col_3</m>. That is, for any 
<me>
\begin{bmatrix} s \\ t \\u \end{bmatrix} \in \Col_3,
</me>
we can find a polynomial  <m>\ve p</m>, of degree 3 or less, such that <m> p(1) = s, p(2) = t, p(3) = u</m>. To show this, you could set up the system of linear equations <md>
<mrow> a + b + c +d = s </mrow>
<mrow> 8a + 4b + 2c + d = t</mrow>
<mrow> 27b + 9 b + 3c + d  = u</mrow>
</md>and solve for the coefficients of <m> \ve p </m>. What is perhaps more elegant is to use the theory of Lagrange interpolation polynomials <fn> https://en.wikipedia.org/wiki/Lagrange_polynomial</fn>. Given any 3 distinct points in <m>\mathbb R^2 </m>, we can always find a degree two polynomial going through these 3 points. In our case, let the points be <m>(1,s), (2,t), (3,u)</m>. The degree two Lagrange polynomial going through these points is
<me>
\ve p(x) = u\left[ \frac{(x-2)(x-3)}{(1-2)(1-3)}\right] + s\left[ \frac{(x-1)(x-3)}{(2-1)(2-3)}\right] + t\left[ \frac{(x-1)(x-2)}{(3-1)(3-2)}\right].
</me>
It is easy to check that <m> p(1) = s, p(2) = t, p(3) = u</m>. Hence <m>\Im(T) = \Col_3</m> and so <m>\Rank(T) = 3</m>.
<me>
\Rank(T) + \Nullity(T) = 1 + 3 = 4 = \Dim(\Poly_3).
</me>
</p>
</li>


<li>
<p>
It will be useful to have the following integrals at hand:
<md>
<mrow>\amp \int_0^\pi \cos(x) = 0 </mrow>
<mrow>\amp \int_0^\pi \sin(x) = 0 </mrow>
<mrow>\amp \int_0^\pi \cos^2(x) = \pi/2 </mrow>
<mrow>\amp \int_0^\pi \sin^2(x) = \pi/2 </mrow>
<mrow>\amp \int_0^\pi \sin(x)\cos(x) = 0</mrow>
<mrow>\amp \int_0^\pi \cos(2x)\cos(x) = 0</mrow>
<mrow>\amp \int_0^\pi \sin(2x)\cos(x) = \frac{4}{3}</mrow>
<mrow>\amp \int_0^\pi \cos(2x)\sin(x) = -\frac{2}{3}</mrow>
<mrow>\amp \int_0^\pi \sin(2x)\sin(x) = 0</mrow>
</md>
</p>

<p>
Now suppose
<me>
\ve f(x) = a + b\cos(x) + c\sin(x) + d\cos(2x) + e\sin(2x) \in \Ker(S).
</me>
Then
<mdn>
  <mrow> \int_0^\pi f(x)\cos(x) \, dx = b\frac{\pi}{2} + e\frac{4}{3} = 0</mrow>
  <mrow> \int_0^\pi f(x)\sin(x) \, dx = c\frac{\pi}{2} - d\frac{2}{3} = 0</mrow>
</mdn>.
Conversely, any <m> f </m> satisfying the linear equations above is certainly in <m> \Ker(S)</m>. Hence
<me>
\Ker(S) = \{a + b\cos(x) + c\sin(x) + d\cos(2x) + e\sin(2x) \,: \\ b\frac{\pi}{2} + e\frac{4}{3} = 0 \text{ and }  c\frac{\pi}{2} - d\frac{2}{3} = 0 \}
</me>We can freely choose <m> a </m> since the constant will not affect the integrals. We are free to choose <m> b </m>, but then <m> e </m> is fully determined by (1) above. Similarly, we can freely choose <m> c </m> but then <m> d </m> is determined by (2).
Hence <me>
\Nullity(S) = 3.
</me>
  </p>

  <p>
We claim that <m> \Im(S) = \Col_2</m>. To see this, suppose 
<me>
\begin{bmatrix} s \\ t \end{bmatrix} \in \Col_2.
</me>
Now consider 
<me>
f(x) = \frac{2s}{\pi}\cos(x) + \frac{2t}{\pi}\sin(x).
</me>
Using the table of integrals above, we see that 
<me>
S(T) = \begin{bmatrix} s \\ t \end{bmatrix} .
</me>
Hence <me>
\Rank(T) = 2.
</me>
  </p>

  <p>
    Since <m>\Dim(\Trig_2) = 5</m>, the Rank-Nullity theorem is verified for <m>S</m>.

  </p>
</li>
        </ol>
      </p>


    </solution>
  </exercise>

  <exercise>
    <statement>
      <p>
        Given an example of a linear map
        <m>T : \Col_4 \rightarrow \Col_4</m> such that <m>\Rank(T) = \Nullity(T)</m>.
      </p>
    </statement>
    <solution>
<p>
Define <m> T </m> by
<me>
T: \begin{bmatrix} x\\y\\z\\w\end{bmatrix} \mapsto \begin{bmatrix} x\\y\\0\\0\end{bmatrix}.
</me>
<me>
\Ker(T) = \left\{\begin{bmatrix} 0\\0\\z\\w\end{bmatrix} \in \Col_4 \right\}.
</me>
and 
<me>
\Im(T) = \left\{\begin{bmatrix} x\\y\\0\\0\end{bmatrix} \in \Col_4 \right\}.
</me>
Both <m>\Ker(T)</m> and <m>\Im(T)</m> are isomorphic to <m>\Col_2</m> and hence <me>
\Rank(T) = \Nullity(2) = 2.
</me>
</p>
    </solution>
  </exercise>

  <exercise>
    <statement>
      <p>
        For each of the following assertions,
        state whether it is <em>true</em> or <em>false</em>.
        If it is true, prove it.
        If it is false, prove that it is false.

        <ol>
          <li>
            <p>
              There exists a linear map <m>T : \mathbb{R}^5 \rightarrow \mathbb{R}^2</m> such that
              <me>
                \Ker(T) = \{ (x_1, x_2, x_3, x_4, x_5) \in \mathbb{R}^5 : x_1 = 3x_2 \text{ and }  x_3 = x_4 = x_5\}
              </me>.
            </p>
          </li>

          <li>
            <p>
              There exists a linear map <m>F : \Trig_3 \rightarrow \Trig_3</m> such that <m>\Rank(T) = \Nullity(T)</m>.
            </p>
          </li>
        </ol>
      </p>
    </statement>

    <solution>

 <p>

        <ol>
          <li>
            <p>
             The statement is false. To see this, notice that if such a map were to exist then its kernel would be 2-dimensional since any choice of <m> x_1</m> and <m>x_3 </m> uniquely determines an element in <m>\Ker(T)</m>. But then by the Rank-Nullity theorem, <m> \Rank(T) = 3 </m> since <m> \mathbb R^5 </m> is 5 dimensional. But <m>\Im(T)</m> is a subspace of <m>\mathbb R^2</m> - which is absurd, since <m> \mathbb R^2 </m> itself is 2-dimensional.
            </p>
          </li>

          <li>
            <p>
              The statemnt is false. Suppose such a map were to exist. Recall that <m> \Dim(\Trig_3) = 7</m>. Then by the Rank-Nullity theorem,
              <me>
              7 = \Rank(T) + \Nullity(T) = 2\Rank(T).
            </me>
            But 7 is odd, so we have a contradiction! Thus no such map can exist.
            </p>
          </li>
        </ol>
      </p>

    </solution>
  </exercise>

  <exercise>
    <statement>
      <p>
        Let <m>f(x,y,z)</m> be a function on
        <m>\mathbb{R}^3</m> and fix a point <m>\ve{p} = (x_0, y_0, z_0) \in \mathbb{R}^3</m>.
        For each vector <m>\ve{u} \in \mathbb{R}^3</m>,
        we can regard the derivative of <m>f</m> in the direction of <m>\ve{u}</m> at <m>\ve{p}</m> as a map
        <md>
          <mrow>D_{\ve{p}} : \mathbb{R}^3 \amp \rightarrow \mathbb{R}</mrow>
          <mrow>\ve{u} \amp \mapsto (\nabla f)(\ve{p}) \cdot \ve{u}</mrow>
        </md>.
        <ol>
          <li>
            <p>
              Show that <m>D_{\ve{p}}</m> as defined above is a linear map.
            </p>
          </li>

          <li>
            <p>
              Consider the example of <m>f(x,y,z) = x^2 + y^2 + z^2</m>.
              Determine <m>\Ker(D_\ve{p})</m> for all points <m>\ve{p} \in \mathbb{R}^3</m>.
            </p>
          </li>
        </ol>
      </p>
    </statement>
    <solution>
      <p>
        <ol>

          <li>
            <p>
              <m>D_\ve{p}</m> being a linear maps follows from the usual properties of the dot product:
              <md>
                <mrow> D_\ve{p}(\ve u + \ve v) \amp = \begin{bmatrix} \frac{\partial f}{\partial x}(\ve p)\\ \frac{\partial f}{\partial y}(\ve p) \\ \frac{\partial f}{\partial z}(\ve p) \end{bmatrix} \cdot (\ve u + \ve v) </mrow>
                <mrow>\amp  = \begin{bmatrix} \frac{\partial f}{\partial x}(\ve p)\\ \frac{\partial f}{\partial y}(\ve p) \\ \frac{\partial f}{\partial z}(\ve p) \end{bmatrix} \cdot \ve u + \begin{bmatrix} \frac{\partial f}{\partial x}(\ve p)\\ \frac{\partial f}{\partial y}(\ve p) \\ \frac{\partial f}{\partial z}(\ve p) \end{bmatrix} \cdot \ve v  </mrow>
                <mrow>\amp = D_\ve{p}(\ve u) + D_\ve{p}(\ve v) </mrow>.
              </md>
              Similarly,
              <md>
                <mrow> D_\ve{p}(k\ve u) \amp = \begin{bmatrix} \frac{\partial f}{\partial x}(\ve p)\\ \frac{\partial f}{\partial y}(\ve p) \\ \frac{\partial f}{\partial z}(\ve p) \end{bmatrix} \cdot \ve ku</mrow>
                <mrow> \amp =\begin{bmatrix} k\frac{\partial f}{\partial x}(\ve p)\\ k\frac{\partial f}{\partial y}(\ve p) \\k \frac{\partial f}{\partial z}(\ve p) \end{bmatrix} \cdot \ve u </mrow>
                <mrow> \amp = k \begin{bmatrix} \frac{\partial f}{\partial x}(\ve p)\\ \frac{\partial f}{\partial y}(\ve p) \\ \frac{\partial f}{\partial z}(\ve p) \end{bmatrix} \cdot \ve u</mrow>
                <mrow> \amp = k D_\ve{p} \cdot \ve u</mrow>.
              </md>
              And so <m>D_\ve{p}</m> is linear.
            </p>
          </li>

          <li>
            <p>
              <m> \ve u = (x_1,y_1,z_1) \in \Ker(D_\ve{p}) </m> if and only if 
              <mdn>
            <mrow> \amp D_\ve{p}(\ve u ) = 0</mrow>
<mrow>\iff \amp \left( \frac{\partial f}{\partial x}(\ve p) , \frac{\partial f}{\partial y}(\ve p) , \frac{\partial f}{\partial z}(\ve p)\right) \cdot (u_0,u_1,u_2) = 0 </mrow>
<mrow>\iff \amp 2x_0x_1 + 2y_0y_1 + 2z_0z_1 = 0.</mrow>
            </mdn>
            Geometrically, <m>\Ker(D_\ve{p}</m> consists of all vectors <m>\ve v</m> that lie tangent to a circle of radius <m>|\ve p |</m> centred at the origin at the point <m>\ve p </m>.
            </p>
          </li>
        </ol>
      </p>
    </solution>
  </exercise>

  <exercise>
    <statement>
      <p>
        Using the Rank-Nullity theorem,
        give a different proof of the fact that the image of the map <m>C</m> in <xref ref="cross-product-example">Example</xref>
        is <m>\{ \ve{u} \in \mathbb{R}^3 : \ve{u} \cdot \ve{a} = 0 \}</m>.
      </p>
    </statement>
     <solution>
    <p>
    <p>
For reference, we reproduce a portion of the proof in in <xref ref="cross-product-example">Example</xref>:
  </p>  
    <p>
        "The kernel of <m>C</m> is the subspace of
        <m>\mathbb{R}^3</m> consisting of all vectors
        <m>\ve{v} \in V</m> such that <m>\ve{a} \times \ve{v} = \ve{0}</m>.
        From the geometric formula for the cross-product,
        <me>
          |\ve{a} \times \ve{v}| = |\ve{a}| |\ve{v}| \sin \theta
        </me>
        where <m>\theta</m> is the angle from <m>\ve{a}</m> to <m>\ve{\theta}</m>,
        we see that
        <me>
          \ve{a} \times \ve{v} = \ve{0}  \Leftrightarrow  \mbox{\(\ve{v}=\ve{0}\) or \(\theta = 0\) or \(\theta= \pi\)} 
        </me>.
      </p>

      <p>
        In other words,
        <m>\ve{v}</m> must be a scalar multiple of <m>\ve{a}</m>.
        So,
        <me>
          \Ker(C) = \{ k \ve{a}, k \in \mathbb{R} \}
        </me>.
      </p>

      <p>
        I claim that the <em>image</em>
        of <m>C</m> is the subspace of <em>all</em>
        vectors perpendicular to <m>\ve{a}</m>, i.e.
        <men>
          \Im(C) := \{ \ve{u} \in \mathbb{R}^3 : \ve{u} \dotp \ve{a} = 0 \}
        </men>.
      </p>

      <p>
        If you believe me, then the picture is as follows:
      </p>

      <image>

<latex-image>
          <![CDATA[\begin{tikzpicture}\draw (0,0) -- (1,2) -- (3,2) -- (2,0) -- (0,0);
  \draw (1.5, 1) -- (1.5,3.5) node[right] {\(\Ker{C}\)};
  \draw (1.5, -0.1) -- (1.5, -2);
  \node at (3.3, 1) {\(\Im(C)\)};  
  \draw[very thick, red, ->] (1.5,1) -- (1.5, 2.5) node[right] {\(\ve{a}\)};\end{tikzpicture}]]>
</latex-image>
      </image>

      <p>
        Let me prove equation <xref ref="image-of-C" />.
        By definition, the image of <m>C</m> is the subspace of
        <m>\mathbb{R}^3</m> consisting of all vectors <m>\ve{w}</m> of the form
        <m>\ve{w} = \ve{a} \times \ve{v}</m> for some <m>\ve{v} \in \mathbb{R}^3</m>.
        This implies that <m>\ve{w}</m> is perpendicular to <m>\ve{a}</m>.""
      </p>
      <p>
        And thus we know that 
        <me>
\Im(C) \subset \{ \ve{u} \in \mathbb{R}^3 : \ve{u} \dotp \ve{a} = 0 \}
      </me>We shall use the Rank-Nullity theorem to show the converse in a fantastically succint way. By the Rank-Nullity theorem
        <md>
        <mrow> \amp \Dim(\mathbb R^3)  = \Nullity(C) + \Rank(C)</mrow>
        <mrow>\implies \amp 3 = 1 + \Rank(C).</mrow>
      </md>
      And so we also know the <m> \Im(C) </m> is a 2-dimensional subspace of <m>\mathbb R^3 </m>. Of course, 
      <me>
       \{ \ve{u} \in \mathbb{R}^3 : \ve{u} \dotp \ve{a} = 0 \}
    </me>
    is also 2-dimensional. But now, if one 2-dimensional subspace is contained in another 2-dimensional subspace then the two subspaces must necessarily be <emp>the same</emp>! Hence 
    <me>
\Im(C) = \{ \ve{u} \in \mathbb{R}^3 : \ve{u} \dotp \ve{a} = 0 \}
  </me>
      </p>
      <p>
        (By using the Rank-Nullity theorem, we managed to bypass the trickest part of <xref ref="cross-product-example"/>!)
      </p>
    </p>
  </solution>
  </exercise>
 
</exercises>

<!-- <solutions divisional="solution answer" />  -->

</section>

