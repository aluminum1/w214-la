

<section xml:id="Ch3Sec5KernelRange">
  <title>Kernel and Image of a Linear Map</title>
  <definition>
    <statement>
      <p>
        Let <m>T : V \rightarrow W</m> be a linear map between vector spaces <m>V</m> and <m>W</m>.
        The <term>kernel</term> of <m>T</m>, written <m>\Ker(T)</m>,
        is the set of all vectors <m>\ve{v} \in V</m> such that are mapped to <m>\ve{0}_W</m> by <m>T</m>.
        That is,
        <me>
          \Ker(T) := \{ \ve{v} \in V : T(\ve{v}) = \ve{0}_W \}
        </me>.
      </p>

      <p>
        The <term>image</term> of <m>T</m>, written <m>\Im(T)</m>,
        is the set of all vectors <m>\ve{w} \in W</m> such that
        <m>\ve{w} = T(\ve{v})</m> for some <m>\ve{v} \in V</m>.
        That is,
        <me>
          \Im(T) := \{ \ve{w} \in W : \ve{w} = T(\ve{v}) \text{ for some } \ve{v} \in V  \}
        </me>
      </p>
    </statement>
  </definition>

  <p>
    See <xref ref="ker_fig"/> and <xref ref="im_fig"/>
    for a schematic representation.
  </p>

  <convention>
    <p>
      Sometimes, to be absolutely clear, I will put a subscript on the zero vector to indicate which vector space it belongs to, e.g.
      <m>\ve{0}_W</m> refers to the zero vector in <m>W</m>,
      while <m>\ve{0}_V</m> refers to the zero vector in <m>V</m>.
    </p>
  </convention>

  <note>
    <p>
      The kernel of <m>T</m> is closely related to the
      <em>nullspace</em> of the matrix for <m>T</m>,
      and another name for the image of <m>T</m> is the
      <em>range</em> of <m>T</m>.
    </p>
  </note>

  <figure xml:id = "ker_fig">
    <caption>An illustration of <m>\Ker(T)</m>, the kernel of <m>T</m> </caption>
    <image>
      <latex-image>
        <![CDATA[\begin{tikzpicture}[scale=1.1]
        \draw (0,0) circle (1);
        \draw (0,0) circle (0.3);
        \draw (3,0) circle (1);
        \node at (0, -1.2) {\(V\)};
        \node at (3, -1.2) {\(W\)};
        \draw (0.083*0.6, 0.493*0.6) -- (3,0);
        \draw (0.083*0.6, -0.493*0.6) -- (3,0);
        \fill[fill=black] (3,0) circle (0.05);
        \node at (3.4, 0) {\(\ve{0}_W\)};
        \node at (0, -0.5) {\(\Ker(T)\)};\end{tikzpicture}]]>
      </latex-image>
    </image>
  </figure>

  <figure xml:id = "im_fig">
    <caption > An illustration of <m>\Im(T)</m>, the image of <m>T</m></caption>
    <image>
      <latex-image>
        <![CDATA[\begin{tikzpicture}[scale=1.1]
        \draw (0,0) circle (1);
        \draw (3,0) circle (0.3);
        \draw (3,0) circle (1);
        \node at (0, -1.2) {\(V\)};
        \node at (3, -1.2) {\(W\)};
        \draw (0.15, 0.987) -- (3.03,0.3);
        \draw (0.15, -0.987) -- (3.03,-0.3);
        \node at (3, -0.5) {\(\Im(T)\)};\end{tikzpicture}]]>
      </latex-image>
    </image>
  </figure>

  <lemma xml:id="ker-im-subspace">
    <statement>
      <p>
        Let <m>T : V \rightarrow W</m> be a linear map.
        Then:

        <ol label="(a)">
          <li>
            <p>
              <m>\Ker(T)</m> is a subspace of <m>V</m>
            </p>
          </li>

          <li>
            <p>
              <m>\Im(T)</m> is a subspace of <m>W</m>
            </p>
          </li>
        </ol>
      </p>
    </statement>
  </lemma>

  <proof>
    <p>
      In both cases, we must check the three requirements for being a subspace.

      <ol label="(a)">
        <li>

          <p>
            <m>\Ker(T)</m> is closed under addition.
          </p>

          <p>
            Suppose <m>\ve{v}</m> and <m>\ve{v}'</m> are in
            <m>\Ker(T)</m>. In other words, <m>T(\ve{v}) = \ve{0}</m> and
            <m>T(\ve{v}') = \ve{0}</m>. We need to show that <m>\ve{v} + \ve{v}'</m>
            is in <m>\Ker(T)</m>, in other words, that <m>T(\ve{v} + \ve{v}') = \ve{0}</m>. Indeed,
            <me>
              T(\ve{v} + \ve{v}') = T(\ve{v}) + T(\ve{v}') = \ve{0} + \ve{0} = \ve{0}
            </me>.
          </p>

        </li>

        <li>
          <p>
            <m>\ve{0}_V \in \Ker(T)</m>.
          </p>

          <p>
            To show that <m>\ve{0}_V</m> is in <m>\Ker(T)</m>, we need to show that
            <m>T(\ve{0}_V) = \ve{0}_W</m>. Indeed, this is true since <m>T</m>
            is a linear map, by <xref ref="lin_map_zero_to_zero">Lemma</xref>.
          </p>
        </li>

        <li>

          <p>
            <m>\Ker(T)</m> is closed under scalar multiplication.
          </p>

          <p>
            Suppose <m>\ve{v} \in \Ker(T)</m> and <m>k \in \mathbb{R}</m> is a scalar.
            We need to show that <m>k \ve{v} \in \Ker(T)</m>, that is, we need to show that <m>T(k \ve{v}) = \ve{0}</m>.
            Indeed,
            <me>
              T(k \ve{v}) = k T(\ve{v}) = k \ve{0} = \ve{0}
            </me>.
          </p>
        </li>
      </ol>
    </p>

    <p>
      Now we check the three requirements for <m>\Im(t)</m>.

      <ol label="(a)">
        <li>

          <p>
            <m>\Im(T)</m> is closed under addition.
          </p>

          <p>
            Suppose <m>\ve{w}</m> and <m>\ve{w}'</m> are in <m>\Im(T)</m>.
            In other words, there exist vectors <m>\ve{v}</m> and <m>\ve{v}'</m>
            in <m>V</m> such that <m>T(\ve{v}) = \ve{w}</m> and <m>T(\ve{v}') = \ve{w}'</m>.
            We need to show that <m>\ve{w} + \ve{w}'</m> is also in <m>\Im(T)</m>,
            in other words, that there exists a vector <m>\ve{u}</m> in <m>V</m>
            such that <m>T(\ve{u}) = \ve{w} + \ve{w}'</m>. Indeed, set
            <m>\ve{u} := \ve{v} + \ve{v}'</m>. Then,
            <me>
              T(\ve{u}) = T(\ve{v} + \ve{v}') = T(\ve{v}) + T(\ve{v}') = \ve{w} + \ve{w}'
            </me>.
          </p>
        </li>

        <li>

          <p>
            <m>\ve{0}_W \in \Im(T)</m>.
          </p>

          <p>
            To show that <m>\ve{0}_W \in \Im(T)</m>, we need to show that there exists
            <m>\ve{v} \in V</m> such that <m>T(\ve{v}) = \ve{0}_W</m>.
            Indeed, choose <m>\ve{v} = \ve{0}_V</m>. Then <m>T(\ve{v}) = T(\ve{0}_V) = \ve{0}_W</m> by <xref ref="lin_map_zero_to_zero">Lemma</xref>.
          </p>
        </li>

        <li>
          <p>
            <m>\Im(T)</m> is closed under scalar multiplication.
          </p>

          <p>
            Suppose <m>\ve{w} \in \Im(T)</m> and <m>k</m> is a scalar.
            We need to show that <m>k \ve{w} \in \Im(T)</m>.
            The fact that <m>\ve{w}</m> is in <m>\Im(T)</m> means that there exists a <m>\ve{v}</m>
            in <m>V</m> such that <m>T(\ve{v}) = \ve{w}</m>. We need to show
            that there exists a <m>\ve{u} \in V</m> such that <m>T(\ve{u}) = k \ve{w}</m>.
            Indeed, set <m>\ve{u} := k \ve{v}</m>. Then
            <me>
              T(\ve{u}) = T(k \ve{v}) = k T(\ve{v}) = k \ve{w}
            </me>.
          </p>
        </li>
      </ol>
    </p>
  </proof>

  <p>
    Now that we know that the kernel and image of a linear map are subspaces,
    and hence vector spaces in their own right,
    we can make the following definition.
  </p>

  <definition>
    <statement>
      <p>
        Let <m>T : V \rightarrow W</m> be a linear map from a finite-dimensional vector space <m>V</m> to a vector space <m>W</m>.
        The <term>nullity</term> of <m>T</m> is the dimension of <m>\Ker(T)</m>,
        and the <term>rank</term> of <m>T</m> is the dimension of <m>\Im(T)</m>:
        <md>
          <mrow>\Nullity(T) \amp := \Dim (\Ker(T))</mrow>
          <mrow>\Rank(T) \amp := \Dim (\Im(T))</mrow>
        </md>
      </p>
    </statement>
  </definition>

  <insight>
    <p>
      The <q>dimension of <m>\Ker(T)</m></q> makes sense because <m>\Ker(T)</m> is a subspace of a finite-dimensional vector space <m>V</m>,
      and hence is finite-dimensional by <xref ref="dim-of-subspace-prop">Proposition</xref>.
      We do not yet know that <m>\Im(T)</m> is finite-dimensional,
      but this will follow from
      <xref ref="rank-nullity-theorem" />.
    </p>
  </insight>

  <example xml:id="cross-product-example">
    <statement>
      <p>
        Let <m>\ve{a} \in \mathbb{R}^3</m> be a fixed nonzero vector.
        Consider the <q>cross product with <m>\ve{a}</m></q> linear map from
        <xref ref="cross_prod_as_linear_map">Example</xref>,
        <md>
          <mrow>C : \mathbb{R}^3 \amp  \rightarrow \mathbb{R}^3</mrow>
          <mrow>\ve{v} \amp \mapsto \ve{a} \times \ve{v}</mrow>
        </md>
      </p>

      <p>
        Determine the kernel, image, nullity and rank of <m>C</m>.
      </p>
    </statement>
    <solution>
      <p>
        The kernel of <m>C</m> is the subspace of
        <m>\mathbb{R}^3</m> consisting of all vectors
        <m>\ve{v} \in V</m> such that <m>\ve{a} \times \ve{v} = \ve{0}</m>.
        From the geometric formula for the cross-product,
        <me>
          |\ve{a} \times \ve{v}| = |\ve{a}| |\ve{v}| \sin \theta
        </me>
        where <m>\theta</m> is the angle from <m>\ve{a}</m> to <m>\ve{\theta}</m>,
        we see that
        <me>
          \ve{a} \times \ve{v} = \ve{0}  \Leftrightarrow  \ve{v}=\ve{0}\text{ or }\theta = 0\text{ or }\theta= \pi
        </me>.
      </p>

      <p>
        In other words,
        <m>\ve{v}</m> must be a scalar multiple of <m>\ve{a}</m>.
        So,
        <me>
          \Ker(C) = \{ k \ve{a}, k \in \mathbb{R} \}
        </me>.
      </p>

      <p>
        I claim that the <em>image</em>
        of <m>C</m> is the subspace of <em>all</em>
        vectors perpendicular to <m>\ve{a}</m>, i.e.
        <men xml:id="image-of-C">
          \Im(C) := \{ \ve{u} \in \mathbb{R}^3 : \ve{u} \dotp \ve{a} = 0 \}
        </men>.
      </p>

      <p>
        If you believe me, then the picture is as follows:
      </p>

      <figure>
        <caption></caption>
        <image>
          <latex-image>
            <![CDATA[\begin{tikzpicture}\draw (0,0) -- (1,2) -- (3,2) -- (2,0) -- (0,0);
            \draw (1.5, 1) -- (1.5,3.5) node[right] {\(\Ker{C}\)};
            \draw (1.5, -0.1) -- (1.5, -2);
            \node at (3.3, 1) {\(\Im(C)\)};
            \draw[very thick, primaryColor, ->] (1.5,1) -- (1.5, 2.5) node[right] {\(\ve{a}\)};\end{tikzpicture}]]>
          </latex-image>
        </image>
      </figure>

      <p>
        Let me prove equation <xref ref="image-of-C" />.
        By definition, the image of <m>C</m> is the subspace of
        <m>\mathbb{R}^3</m> consisting of all vectors <m>\ve{w}</m> of the form
        <m>\ve{w} = \ve{a} \times \ve{v}</m> for some <m>\ve{v} \in \mathbb{R}^3</m>.
        This implies that <m>\ve{w}</m> is perpendicular to <m>\ve{a}</m>.
        This was the <q>easy</q> part.
        The <q>harder</q> part is to show the converse.
        That is, we need to show that if <m>\ve{u}</m> is perpendicular to <m>\ve{a}</m>,
        then <m>\ve{u}</m> is in the image of <m>C</m>,
        i.e. there exists a vector <m>\ve{v}</m> such that <m>C(\ve{v}) = \ve{u}</m>.
      </p>

      <p>
        Indeed, we can choose <m>\ve{v}</m> to be the vector obtained by rotating <m>\ve{u}</m> by 90 degrees clockwise in the plane <m>I</m>,
        and scaling it appropriately:
      </p>

      <figure>
        <caption></caption>
        <image>
          <latex-image>
            <![CDATA[\begin{tikzpicture}\draw (0,0) -- (1,2) -- (3,2) -- (2,0) -- (0,0);
            \draw[very thick, primaryColor, ->] (1.5,1) -- (1.5, 2.5) node[right] {\(\ve{a}\)};
            \draw[very thick, secondaryColor, ->] (1.5,1) -- (1.75, 1.5) node[right, xshift=-6pt, yshift=3pt] {\(\ve{u}\)};
            \draw[very thick, ternaryColor, ->] (1.5,1) -- (2, 1) node[xshift=-4pt, right] {\(\ve{v}\)};\end{tikzpicture}]]>
            </latex-image>
        </image>
      </figure>

      <p>
        In terms of a formula, we have
        <me>
          \ve{v} = \frac{|\ve{u}|}{|\ve{a}|} \ve{u} \times \ve{a}
        </me>.
      </p>

      <p>
        Note that this is not the <em>only</em>
        vector <m>\ve{v}</m> such that <m>C(\ve{v}) = \ve{u}</m>.
        Indeed, if we add to <m>\ve{v}</m> any vector that lies on the line through <m>\ve{a}</m>,
        the resulting vector
        <me>
          \tilde{\ve{v}} = \ve{v} + k \ve{a}
        </me>
        <em>also</em> satisfies <m>C(\tilde{\ve{v}}) = \ve{u}</m>, since
        <me>
          C(\tilde{\ve{v}}) = C(\ve{v} + k \ve{a}) = C(\ve{v}) + C(k \ve{a}) = \ve{u} + \ve{0} = \ve{u}
        </me>.
      </p>
    </solution>
  </example>

  <example>
    <statement>
      <p>
        Determine the kernel, image, nullity and rank of the linear map
        <md>
          <mrow>I : \Trig_2 \amp  \rightarrow \mathbb{R}</mrow>
          <mrow>f \amp  \mapsto \int_0^\pi f(x) dx </mrow>
        </md>.
      </p>
    </statement>
    <solution>
      <p>
        The kernel of <m>I</m> consists of all degree 2 trigonometric polynomials
        <me>
          f(x) = a_0 + a_1 \cos x + b_1 \sin x + a_2 \cos 2x + b_2 \sin 2x
        </me>
        such that
        <me>
          \int_0^\pi (a_0 + a_1 \cos x + b_1 \sin x + a_2 \cos 2x + b_2 \sin 2x) \, dx = 0
        </me>.
      </p>

      <p>
        Performing the integrals, this becomes the equation
        <me>
          \pi a_0 + 2 b_1 = 0
        </me>
        with no constraints on the other constants <m>a_1, a_2, b_2</m>.
        In other words,
        <me>
          \Ker(I) = \left\{ \text{ all trigonometric polynomials of the form  } \\ (a_0(1 - \frac{\pi}{2} \sin x) + a_1 \cos x + a_2 \cos{2x} + b_2 \sin{2x}), \text{ where } (a_0, a_1, a_2, b_2 \in \mathbb{R}). \right\}
        </me>
      </p>

      <p>
        Hence <m>\Nullity(I) = \Dim (\Ker(I)) = 4</m>.
      </p>

      <p>
        The image of <m>I</m> consists of all real numbers
        <m>p \in \mathbb{R}</m> such that there exists a
        <m>f \in \Trig_2</m> such that <m>I(f) = p</m>.
        I claim that
        <me>
          \Im(I) = \mathbb{R}
        </me>.
      </p>

      <p>
        Indeed, given <m>p \in \mathbb{R}</m>,
        we may choose <m>f(x) = \frac{p}{2} \sin{x}</m>, since
        <me>
          I(f) = \frac{p}{2} \int_0^\pi \sin{x} \, dx  = p
        </me>.
      </p>

      <p>
        Hence <m>\Im(I) = \mathbb{R}</m>, and <m>\Rank(I) = 1</m>.
      </p>

      <p>
        Note that the choice of <m>f(x) = \frac{p}{2} \sin(x)</m> satisfying <m>I(f) = p</m> is not unique.
        We could set <m>\tilde{f} = f + g</m> where
        <m>g \in \Ker(I)</m> and we would still have <m>I(\tilde{f})=p</m>:
        <me>
          I(\tilde{f}) = I(f + g) = I(f) + I(g) =  p + 0 = p
        </me>.
      </p>
    </solution>
  </example>

  <example xml:id="old_example_ker_range_poly">
    <statement>
      <p>
        Consider the function
        <md>
          <mrow>T : \Poly_2 \amp  \rightarrow \mathbb{R}^2</mrow>
          <mrow>p \amp  \mapsto (p(1), p'(1))</mrow>
        </md>.
      </p>

      <p>
        Show that <m>T</m> is a linear map,
        and determine its kernel, image, rank and nullity.
      </p>
    </statement>
    <solution>
      <p>
        We first show that <m>T</m> is a linear map.
        Let <m>p,q \in \Poly_2</m>.
        Then
        <md>
          <mrow>T(p + q) \amp = ( (p+q)(1), \, (p+q)'(1) )  \amp \amp  \text{(Defn of } T)</mrow>
          <mrow>\amp = (p(1) + q(1), \, (p+q)'(1) ) \amp \amp  \text{(Defn of the function } p+q)</mrow>
          <mrow>\amp = (p(1) + q(1), \, (p'+q')(1) ) \amp \amp  ((p+q)' = p'+q')</mrow>
          <mrow>\amp = (p(1) + q(1), \, p'(1) + q'(1)) \amp \amp  \text{(Defn of the function } p' + q')</mrow>
          <mrow>\amp = (p(1), \, p'(1)) + (q(1), \, q'(1)) \amp \amp  \text{(Defn of addition in } \mathbb{R}^2)</mrow>
          <mrow>\amp = T(p) + T(q)</mrow>
        </md>.
      </p>

      <p>
        The proof of <m>T(kp) = kT(p)</m> is similar.
      </p>

      <p>
        The kernel of <m>T</m> is the set of all polynomials
        <me>
          p(x) = a_0 + a_1 x + a_2 x^2
        </me>
        such that <m>T(p) = (0,0)</m>.
        This translates into the equation
        <me>
          (a_0 + a_1 + a_2, \, a_1 + 2 a_2) = (0,0)
        </me>.
      </p>

      <p>
        This in turn translates into two equations:
        <md>
          <mrow> a_0 + a_1 + a_2 \amp = 0 </mrow>
          <mrow> a_1 + 2a_2 \amp = 0 </mrow>
        </md>
        whose solution is <m>a_2 = t</m>,
        <m>a_1 = - 2t</m>, <m>a_0 = -t</m>,
        where <m>t \in \mathbb{R}</m>.
        Hence
        <me>
          \Ker(T) =  \left\{ \text{ all polynomials of the form }  -t -2t x + t x^2\text{ where } t \in \mathbb{R}  \right\}
        </me>.
      </p>

      <p>
        Hence <m>\Nullity(T) = 1</m>.
      </p>

      <p>
        The image of <m>T</m> is the set of all
        <m>(v,w) \in \mathbb{R}^2</m> such that there exists a polynomial
        <m>p = a_0 + a_1 x + a_2 x^2</m> in <m>\Poly_2</m> such that <m>T(p) = (v,w)</m>.
        So, <m>(v,w)</m> is in the image of <m>T</m>
        if and only if we can find a polynomial <m>p = a_0 + a_1x + a_2 x^2</m> such that
        <me>
          (a_0 + a_1 + a_2, a_1 + 2a_2) = (v,w)
        </me>.
      </p>

      <p>
        In other words,
        <m>(v,w)</m> is in the image of <m>T</m> if and only if the equations
        <md>
          <mrow> a_0 + a_1 + a_2 \amp = v </mrow>
          <mrow>a_1 + 2a_2 \amp = w</mrow>
        </md>
        have a solution for some <m>a_0, a_1, a_2</m>.
        But these equations <em>always</em> have a solution,
        for <em>all</em> <m>(v,w) \in \mathbb{R}^2</m> is.
        For instance, one solution is
        <me>
          a_2 = 0 ,  \, a_1 = w, \, a_0 = v - w
        </me>
        which corresponds to the polynomial
        <men xml:id="one-soln-for-preimage">
          p(x) = v-w + wx
        </men>.
      </p>

      <p>
        Note that indeed <m>T(p) = (v,w)</m>.
        Hence,
        <me>
          \Im(T) = \{\text{all }  (v,w) \in \mathbb{R}^2 \} = \mathbb{R}^2
        </me>.
      </p>

      <p>
        Hence <m>\Rank (T) = \Dim (\Im(T)) = 2</m>.
      </p>

      <p>
        Note that the choice of the polynomial
        <m>p(x) = v-w + w x</m> from <xref ref="one-soln-for-preimage" /> which satisfies <m>T(p) = (v,w)</m> is not the
        <em>only</em> possible choice.
        Indeed, any polynomial of the form <m>\tilde{p} = p + q</m> where
        <m>q \in \Ker(T)</m> will also satisfy <m>T(\tilde{p}) = (v,w)</m>, since
        <me>
          T(\tilde{p}) = T(p + q) = T(p) + T(q) = (v,w) + (0,0) = (v,w)
        </me>.
      </p>
    </solution>
  </example>

  <example xml:id="modification_r_n_ex">
    <statement>
      <p>
        This example is a modification of <xref ref="old_example_ker_range_poly"/>. Determine the kernel, image, rank and nullity of the following linear map:
        <md>
          <mrow> T : \Poly_2 \amp \rightarrow \Col_3</mrow>
          <mrow> p : \amp \mapsto \begin{bmatrix} p(1) \\ p'(1) \\ p(2) - \frac{1}{2}p''(3) \end{bmatrix}</mrow>
        </md>
      </p>
    </statement>
    <solution>
      <p>
        We start by computing <m>\Ker(T)</m>. We have
        <men xml:id="p_in_kernel_1">
          p \in \Ker(T) \quad \Leftrightarrow \quad T(p) = \begin{bmatrix} 0 \\ 0 \\ 0 \end{bmatrix}
        </men>
      </p>
      <p>
        Write
        <me>
          p = a + bx + cx^2
        </me>
        Then equation <xref ref="p_in_kernel_1"/> becomes:
        <me>
          \begin{bmatrix} a + b + c \\ b + 2c \\ a + 2b + 3c  \end{bmatrix} = \begin{bmatrix} 0 \\ 0 \\ 0 \end{bmatrix}
        </me>
        This equation between column vectors is satisfied if and only if the following linear equations are simultaneously satisfied:
        <md>
          <mrow> a + b + c \amp = 0 </mrow>
          <mrow> b + 2c \amp = 0</mrow>
          <mrow> a + 2b + 3c \amp = 0</mrow>
        </md>
        We observe that the third equation is equal to the sum of the first equation and the second equation. So when we transform these equations into row-echelon form, we get:
        <md>
         <mrow> a + b + c \amp = 0 </mrow>
         <mrow> b + 2c \amp = 0 </mrow>
        </md>
      </p>
      <p>
        The general solution is:
        <me>
          c = t, \, b = -2t, \, a = t, \quad t \in \mathbb{R}
        </me>
        Therefore,
        <me>
          \Ker(T) = \{ t - 2t x + tx^2 : t \in \mathbb{R}\}
        </me>
      </p>
      <p>
        A basis for <m>\Ker(T)</m> is obtained by setting the parameter <m>t = 1</m>:
        <me>
          \text{Basis for } \Ker(T) = \bopen 1 - 2x + x^2 \bclose
        </me>
        So
        <me>
          \Nullity(T) = \Dim(\Ker(T)) = 1.
        </me>
      </p>
      <p>
        Now let us compute <m>\Im(T)</m>. We have
        <md>
          <mrow> \mat{w} \equiv \begin{bmatrix} w_1 \\ w_2 \\ w_3 \end{bmatrix} \in \Im(T)  </mrow>
          <mrow> \Leftrightarrow \text{there exists } p \in \Poly_2 \text{ such that } T(p) = \begin{bmatrix} w_1 \\ w_2 \\ w_3 \end{bmatrix} </mrow>
        </md>
      </p>
      <p>
        Write
        <m>
          p = a + bx + cx^2.
        </m>
        Then
        <md>
          <mrow> T(p) = \begin{bmatrix} w_1 \\ w_2 \\ w_3 \end{bmatrix} </mrow>
          <mrow> \Leftrightarrow \begin{bmatrix} a + b + c \\ b + 2c \\ a + 2b + 3c \end{bmatrix} = \begin{bmatrix} w_1 \\ w_2 \\ w_3 \end{bmatrix}</mrow>
        </md>
        In other words,<m>\mat{w} \in \Im(T)</m> if and only if there exists <em>some</em> solution to the following equations for <m>a,b,c</m>:
        <md>
          <mrow>a + b + c \amp = w_1</mrow>
          <mrow> b + 2c \amp= w_2</mrow>
          <mrow>a + 2b + 3c \amp = w_3</mrow>
        </md>
      </p>
      <p>
        Let us solve these equations using row reduction:
        <md>
          <mrow>\left[ \begin{array}{ccc|c}
            1 \amp 1 \amp 1 \amp w_1 \\
            0 \amp 1 \amp 2 \amp w_2 \\
            1 \amp 2 \amp 3 \amp w_3
            \end{array}\right]</mrow>
          <mrow>
            \xrightarrow{R_3 - R_1}
            \left[ \begin{array}{ccc|c}
            1 \amp 1 \amp 1 \amp w_1 \\
            0 \amp 1 \amp 2 \amp w_2 \\
            0 \amp 1 \amp 2 \amp w_3 - w_1
            \end{array}\right]
          </mrow>
          <mrow>
            \xrightarrow{R_3 - R_2}
            \left[ \begin{array}{ccc|c}
            1 \amp 1 \amp 1 \amp w_1 \\
            0 \amp 1 \amp 2 \amp w_2 \\
            0 \amp 0 \amp 0 \amp w_3 - w_1 - w_2
            \end{array}\right]
          </mrow>
        </md>
      </p>
      <p>
        So: there is <em>no</em> solution for <m>a,b,c</m> unless <m>w_3 - w_1 - w_2 = 0</m>, because otherwise we will have an equation of the form 'zero equals nonzero value'. Moreover, <em>if</em> <m>w_3 - w_1 - w_2</m>, then the above equations <em>can</em> be solved for <m>a,b,c</m>, because then they are in augmented row echelon form with no invalid rows. Therefore,
        <me>
          \Im(T) = \left\{ \begin{bmatrix} w_1 \\ w_2 \\ w_3 \end{bmatrix} : -w_1 -w_2 + w_3 = 0 \right\}.
        </me>
      </p>
      <p>
        So, a basis for <m>\Im(T)</m> is given by:
        <me>
          \bopen \begin{bmatrix}  1 \\ 0 \\ 1 \end{bmatrix}, \begin{bmatrix} 0 \\ 1 \\ 1 \end{bmatrix} \bclose
        </me>
        and hence
        <me>
          \Rank(T) = 2.
        </me>
      </p>
    </solution>
  </example>

  <theorem xml:id="rank-nullity-theorem">
    <title>The Rank-nullity theorem</title>
    <statement>
      <p>
        Let <m>T : V \rightarrow W</m> be a linear map from a finite-dimensional vector space <m>V</m> to a vector space <m>W</m>.
        Then
        <me>
          \Nullity(T) + \Rank(T) = \Dim(V)
        </me>.
      </p>
    </statement>

  <proof>
    <p>
      Let <m>\basis{B} = \bopen \ve{e}_1, \ldots, \ve{e}_k \bclose</m> be a basis for <m>\Ker(T)</m>.
      Since <m>\basis{B}</m> is a list of linearly independent vectors in <m>V</m>,
      we can extend it to a basis <m>\basis{C} = \bopen \ve{e}_1, \ldots, \ve{e}_k, \ve{f}_1, \ldots, \ve{f}_p \bclose</m> for <m>V</m>,
      by <xref ref="first_corollary_please">Corollary</xref>.
      I claim that
      <me>
        \basis{D} := \bopen T(\ve{f}_1), \ldots, T(\ve{f}_p) \bclose
      </me>
      is a basis for <m>\Im(T)</m>.
      If I can prove that, then we are done, since then we have
      <md>
        <mrow>\Nullity(T) + \Rank(T) \amp = k + p</mrow>
        <mrow>\amp = \Dim(V)</mrow>
      </md>.
    </p>

    <p>
      Let us prove that <m>\basis{D}</m> is a basis for <m>\Im(T)</m>.
    </p>

    <p>
      <em><m>\basis{D}</m> is linearly independent</em>.
      Suppose
      <me>
        b_1 T(\ve{f}_1) + \cdots + b_p T(\ve{f}_p) = \ve{0}_W
      </me>.
    </p>

    <p>
      We recognize the left hand side as <m>T(b_1 \ve{f}_1 + \cdots + b_p \ve{f}_p)</m>.
      Hence
      <me>
        b_1 \ve{f}_1 + \cdots + b_p \ve{f}_p \in \Ker(T)
      </me>
      which means we can write it as a linear combination of the vectors in <m>\basis{B}</m>,
      <me>
        b_1 \ve{f}_1 + \cdots + b_p \ve{f}_p = a_1 \ve{e}_1 + \cdots + a_k \ve{e}_k
      </me>.
    </p>

    <p>
      Bringing all terms onto one side, this becomes the equation
      <me>
        -a_1 \ve{e}_1 - \cdots -a_k \ve{e}_k + b_1 \ve{f}_1 + \cdots + b_p \ve{f}_p = \ve{0}_V
      </me>.
    </p>

    <p>
      We recognize the left hand side as a linear combination of the <m>\basis{C}</m> basis vectors.
      Since they are are linearly independent,
      all the scalars must be zero.
      In particular, <m>b_1 = \cdots = b_p = 0</m>,
      which is what we wanted to prove.
    </p>

    <p>
      <em><m>\basis{D}</m> spans <m>W</m></em>.
      Suppose <m>\ve{w} \in \Im(T)</m>.
      We need to show that <m>\ve{w}</m> is a linear combination of the vectors from <m>\basis{D}</m>.
      Since <m>\ve{w}</m> is in the image of <m>T</m>,
      there exists <m>\ve{v} \in V</m> such that <m>T(\ve{v}) = \ve{w}</m>.
      Since <m>\basis{C}</m> is a basis for <m>V</m>, we can write
      <me>
        \ve{v} = a_1 \ve{e}_1 + \cdots + a_k \ve{e}_k + b_1 \ve{f}_1 + \cdots + b_p \ve{f}_p
      </me>
      for some scalars <m>a_1, \ldots, a_k, b_1, \ldots, b_p</m>.
      Then
      <md>
        <mrow>\ve{w} \amp =   T(\ve{v})</mrow>
        <mrow>\amp = T(a_1 \ve{e}_1 + \cdots + a_k \ve{e}_k + b_1 \ve{f}_1 + \cdots + b_p \ve{f}_p)</mrow>
        <mrow>\amp = a_1 T(\ve{e}_1) + \cdots + a_k T(\ve{e}_k) + b_1 T(\ve{f}_1) + \cdots + b_p T(\ve{f}_p)</mrow>
        <mrow>\amp = b_1 T(\ve{f}_1) + \cdots + b_p T(\ve{f}_p) \amp \amp  (\ve{e}_i \in \Ker(T))</mrow>
      </md>
      so that <m>\ve{w}</m> is indeed a linear combination of the vectors from <m>\basis{D}</m>.
    </p>
  </proof>
</theorem>

  <example>
    <title>The identity map on a vector space</title>
    <statement>
      <p>
        Consider the identity map on a finite-dimensional vector space <m>V</m>:
        <me>
          \id_V : V \rightarrow V
        </me>
        We have
        <me>
          \Ker(\id_V) = \{\ve{0}\}
        </me>
        because the only vector sent to zero by the identity map is the zero vector itself. Therefore,
        <me>
          \Nullity(\id_V) = 0.
        </me>
        Similarly,
        <me>
          \Im(\id_V) = V
        </me>
        because <em>every</em> vector <m>\ve{v} \in V</m> is in the image of <m>\id_V</m>. Indeed, we have <m>\id_V (\ve{v}) = \ve{v}</m>, proving that <m>\ve{v} \in \Im(\id_V)</m>. Hence,
        <me>
          \Rank(\id_V) = \Dim(V).
        </me>
        So indeed the Rank Nullity theorem (<xref ref="rank-nullity-theorem"/>) is true in this case, as
        <me>
          \underbrace{\Rank(\id_V)}_{=\Dim(V)} + \underbrace{\Ker(\id_V)}_{=0} = \Dim(V).
        </me>
      </p>
    </statement>
  </example>

  <example>
    <title>The zero map</title>
    <statement>
      <p>
        Consider the zero map <m>Z</m>on a finite-dimensional vector space <m>V</m>:
        <md>
          <mrow> Z : V \amp \rightarrow V</mrow>
          <mrow> \ve{v} \amp \mapsto \ve{0} </mrow>
        </md>
        We have
        <me>
          \Ker(Z) = V
        </me>
        because <em>every</em> vector <m>\ve{v} \in V</m> is sent to the zero vector by <m>Z</m>. So,
        <me>
          \Nullity(Z) = \Dim(V).
        </me>
        Similarly, we have
        <me>
          \Im(Z) = \{\ve{0}\}
        </me>
        because the <em>only</em> vector in the image of <m>Z</m> is the zero vector <m>\ve{0}</m>. That is because, for all vectors <m>\ve{v} \in V</m>, <m>Z(\ve{v}) = \ve{0}</m>. So,
        <me>
          \Rank(Z) = 0.
        </me>
        Hence the Rank-Nullity theorem (<xref ref="rank-nullity-theorem"/>) is true in this case, as
        <me>
          \underbrace{\Rank(Z)}_{=0} + \underbrace{\Ker(Z)}_{=\Dim(V)} = \Dim(V).
        </me>
      </p>
    </statement>
  </example>

  <example>
    <title>
      Verifying that <xref ref="modification_r_n_ex"/> satisfies the Rank-Nullity Theorem
    </title>
    <statement>
      <p>
        Let us verify that the linear map <m>T</m> from <xref ref="modification_r_n_ex"/> satisfies <xref ref="rank-nullity-theorem"/>. In <xref ref="modification_r_n_ex"/>, we computed that
        <me>
          \Nullity(T) = 1, \quad \Rank(T) = 2.
        </me>
        Hence,
        <me>
          \underbrace{\Rank(T)}_{=2} + \underbrace{\Nullity(T)}_{=1} = \underbrace{\Dim(\Poly_2)}_{=3}
        </me>
        so it indeed satisfies <xref ref="rank-nullity-theorem"/>.
      </p>
    </statement>
  </example>

  <exercises>
    <exercise>
      <statement>
        <p>
           Let <m>T:\Row_2\to \Row_3</m> be the linear map defined by <m>T(x,y) = (x-y,2x-2y, y-x)</m>.
           For each of the following vectors, determine whether it is an element of <m>\Ker(T)</m>, <m>\Im(T)</m> or both or neither:
        <ol label="(a)" cols="3">
          <li> v_1 = (0,0) </li>
          <li> v_2 = (0,0,0) </li>
          <li> v_3 = (2,1) </li>
          <li> v_4 = (4,4) </li>
          <li> v_5 = (1,2,3) </li>
          <li> v_6 = (1,2,-1) </li>
        </ol>
        </p>
      </statement>
      <answer>
        <p>
          <m>v_1</m> and <m>v_4</m> are in the kernel and <m>v_2</m> and <m>v_6</m> are in the image.
        </p>
      </answer>
      <solution>
        <p>
        <ol label="(a)">
          <li>
            The vector <m>(0,0)</m> is in <m>Row_2</m>, not <m>Row_3</m>, so it is a candidate to be in the kernel, but not the image (wrong type). It is in the kernel, since <m>T(0,0)=(0,0,0)</m>. In fact, the zero vector of the domain will always be in the kernel.
          </li>
          <li>
            The vector <m>(0,0,0)</m> is not in the domain <m>Row_2</m> so cannot be in the kernel. But it is in the image, since <m>T(0,0)=(0,0,0)</m>. Again, the zero vector of the codomain will always be in the image of a linear map.
          </li>
          <li>
            The vector <m>(2,1)</m> cannot be in the image, so we only check if it is in the kernel. To do this, we check whether <m>T(2,1)=(0,0,0)</m>. But <m>T(2,1) = (2-1,4,2,1-2) = (1,2,-1)</m>. Since this is not the zero vector, <m>(2,1)</m> is not in the kernel of <m>T</m>.
          </li>
          <li>
            We have <m>T(4,4) = (4-4,8-8,4-4) = (0,0,0)</m>. Since <m>(4,4)</m> is mapped to the zero vector, <m>(4,4)</m> is in the kernel of <m>T</m>.
          </li>
          <li>
            To determine whether <m>(1,2,3)</m> is in the image of <m>T</m>, we need to find out whether there exist <m>x,y</m> such that <m>T(x,y) = (1,2,3)</m>, or equivalently <m>x-y,2x-2y,y-x) = (1,2,3)</m>. So we need to solve the system
            <md>
              <mrow>  x-y \amp = 1 </mrow>
              <mrow> 2x-2y \amp = 2 </mrow>
              <mrow> -x+y \amp = 3 </mrow>
            </md>.
            By performing row reduction on this system, we see that it is equivalent to
            <md>
              <mrow> x-y \amp = 1 </mrow>
              <mrow> 0 \amp = 0 </mrow>
              <mrow> 0 \amp = 4 </mrow>
            </md>.
            This last equation is a contradiction, so there are no solutions and thus <m>(1,2,3)</m> is not in the image of <m>T</m>.
          </li>
          <li>
            We do the same thing as for (e), but this time the system
            <md>
              <mrow> x-y \amp = 1</mrow>
              <mrow> 2x-2y \amp = 2</mrow>
              <mrow> -x+y \amp = -1 </mrow>
            </md>
            reduces to
            <md>
              <mrow> x-y \amp = 1 </mrow>
              <mrow> 0 \amp = 0 </mrow>
              <mrow> 0 \amp = 0 </mrow>
            </md>
            which has the solution <m>x=1</m>, <m>y=0</m> (and many others). Thus the vector <m>(1,2,-1)</m> is in the image of <m>T</m>, because, for example <m>(1,2,-1)=T(1,0)</m>.
          </li>
        </ol>
        </p>
      </solution>
    </exercise>

  <exercisegroup>
    <introduction>
      <p>
        In <xref ref="exercise-RankNullity-group-1st" /> to <xref ref="exercise-RankNullity-group-last" />,
        verify the Rank-Nullity theorem for the given linear maps.
        That is, for each map <m>T</m>,
        <ol label="(a)">
          <li>
            determine <m>\Ker(T)</m> and <m>\Im(T)</m> explicitly,
          </li>
          <li>
            determine the dimension of <m>\Ker(T)</m> and <m>\Im(T)</m>,
          </li>
          <li>
            check that these numbers satisfy the Rank-Nullity theorem.
          </li>
        </ol>
      </p>
    </introduction>
  <exercise xml:id="exercise-RankNullity-group-1st">
    <statement>
      <p>
        The identity map <m>\id_V : V \rightarrow V</m> on a finite-dimensional vector space <m>V</m>.
      </p>
    </statement>
    <solution>
      <p>
        <m>\id_V</m> sends only a single vector to <m>0</m>, namely the vector <m>\ve 0_v</m>. Thus <m>\Ker(\id_v) = \{\ve 0_v\}</m> and hence <m>\Nullity(\id_v) = 0</m>. We also have <m>\Im(\id_V) = V</m>  and so <m>\Rank(\id_V) = \Dim(V) </m>. The equation
        <me>
          \Dim V + 0 = \Dim V .
        </me>
        verifies the Rank-Nullity Theorem for this example.
      </p>
    </solution>
  </exercise>

  <exercise>
    <statement>
      <p>
        The zero map
        <md>
          <mrow>Z : V \amp  \rightarrow V</mrow>
          <mrow>\ve{v} \amp  \mapsto \ve{0}</mrow>
        </md>
        on a finite-dimensional vector space <m>V</m>.
      </p>
    </statement>
    <solution>
      <p>
        The zero map spends every element in <m>V </m> to <m> \ve 0 </m>. Hence <m>\Ker(Z) = V </m> and so <m> \Nullity(Z) = \Dim V </m>. For the same reason <m>\Im(Z) = \{0\}</m> and thus <m>\Rank(Z) = 0 </m>. The equation
        <me>
          \Dim V + 0 = \Dim V .
        </me>
        verifies the Rank-Nullity Theorem for this example.
      </p>
    </solution>
  </exercise>

  <exercise>
    <statement>
      <p>
        The map
        <md>
          <mrow>T : \Poly_3 \amp  \rightarrow \Col_3</mrow>
          <mrow>p \amp  \mapsto \begin{bmatrix} p(1) \\ p(2) \\ p(3)\end{bmatrix}</mrow>
        </md>
      </p>
    </statement>
    <solution>
      <p>
        <m> \ve p(x) \in \Ker(T) </m> if and only if
        <me>
          p(1) = p(2) = p(3) = 0
        </me>.
        But any degree 3 polynomial with <m>1, 2</m> and <m> 3</m> as roots must be of the form
        <me>
          a(x-1)(x-2)(x-3)
        </me>
        where <m> a \in \mathbb R </m>. Conversely, any element of this form is in <m> \Ker T </m>. Hence
        <me>
          \Ker(T) = \{a(x-1)(x-2)(x-3) \in \Poly_3 \, : \, a \in \mathbb R\}
        </me>
        and thus <m> \Nullity(T)  = 1 </m>.
      </p>
      <p>
        I claim that <m>\Im(T) = \Col_3</m>. That is, for any
        <me>
          \begin{bmatrix} s \\ t \\u \end{bmatrix} \in \Col_3,
        </me>
        we can find a polynomial  <m>\ve p</m>, of degree 3 or less, such that <m> p(1) = s, p(2) = t, p(3) = u</m>. To show this, you could set up the system of linear equations
        <md>
          <mrow> a + b + c +d = s </mrow>
          <mrow> 8a + 4b + 2c + d = t</mrow>
          <mrow> 27b + 9 b + 3c + d  = u</mrow>
        </md>
        and solve for the coefficients of <m> \ve p </m>. What is perhaps more elegant is to use the theory of Lagrange interpolation polynomials <fn> https://en.wikipedia.org/wiki/Lagrange_polynomial</fn>. Given any 3 distinct points in <m>\mathbb R^2 </m> (no two on the same vertical line), we can always find a degree two polynomial going through these 3 points. In our case, let the points be <m>(1,s), (2,t), (3,u)</m>. The degree two Lagrange polynomial going through these points is
        <me>
          \ve p(x) = u\left[ \frac{(x-2)(x-3)}{(1-2)(1-3)}\right] + s\left[ \frac{(x-1)(x-3)}{(2-1)(2-3)}\right] + t\left[ \frac{(x-1)(x-2)}{(3-1)(3-2)}\right].
        </me>
        It is easy to check that <m> p(1) = s, p(2) = t, p(3) = u</m>. Hence <m>\Im(T) = \Col_3</m> and so <m>\Rank(T) = 3</m>.
        <me>
          \Rank(T) + \Nullity(T) = 1 + 3 = 4 = \Dim(\Poly_3).
        </me>
      </p>
    </solution>
  </exercise>

  <exercise>
    <statement>
      <p>
        The map
        <md>
          <mrow>S : \Trig_2 \amp  \rightarrow \Col_2</mrow>
          <mrow>f \amp  \mapsto \begin{bmatrix} \displaystyle \int_0^\pi f(x) \cos x dx \\
          \displaystyle \int_0^\pi f(x) \sin x dx \end{bmatrix} </mrow>
        </md>
      </p>
    </statement>
    <solution>
      <p>
        It will be useful to have the following integrals at hand:
        <md>
          <mrow>\amp \int_0^\pi \cos(x) = 0 </mrow>
          <mrow>\amp \int_0^\pi \sin(x) = 0 </mrow>
          <mrow>\amp \int_0^\pi \cos^2(x) = \pi/2 </mrow>
          <mrow>\amp \int_0^\pi \sin^2(x) = \pi/2 </mrow>
          <mrow>\amp \int_0^\pi \sin(x)\cos(x) = 0</mrow>
          <mrow>\amp \int_0^\pi \cos(2x)\cos(x) = 0</mrow>
          <mrow>\amp \int_0^\pi \sin(2x)\cos(x) = \frac{4}{3}</mrow>
          <mrow>\amp \int_0^\pi \cos(2x)\sin(x) = -\frac{2}{3}</mrow>
          <mrow>\amp \int_0^\pi \sin(2x)\sin(x) = 0</mrow>
        </md>
      </p>

      <p>
        Now suppose
        <me>
        \ve f(x) = a + b\cos(x) + c\sin(x) + d\cos(2x) + e\sin(2x) \in \Ker(S).
        </me>
        Then
        <mdn>
          <mrow> \int_0^\pi f(x)\cos(x) \, dx = b\frac{\pi}{2} + e\frac{4}{3} = 0</mrow>
          <mrow> \int_0^\pi f(x)\sin(x) \, dx = c\frac{\pi}{2} - d\frac{2}{3} = 0</mrow>
        </mdn>.
        Conversely, any <m> f </m> satisfying the linear equations above is certainly in <m> \Ker(S)</m>. Hence
        <md>
          <mrow>
          \Ker(S) = \{a + b\cos(x) + c\sin(x) + d\cos(2x) + e\sin(2x) \,: </mrow>
          <mrow>
           b\frac{\pi}{2} + e\frac{4}{3} = 0 \quad\text{and}\quad  c\frac{\pi}{2} - d\frac{2}{3} = 0 \} </mrow>
        </md>.
        We can freely choose <m> a </m> since the constant will not affect the integrals. We are free to choose <m> b </m>, but then <m> e </m> is fully determined by the first condition above. Similarly, we can freely choose <m> c </m> but then <m> d </m> is determined by the second condition above.
        Hence <me>
        \Nullity(S) = 3.
        </me>
      </p>

      <p>
        We claim that <m> \Im(S) = \Col_2</m>. To see this, suppose
        <me>
          \begin{bmatrix} s \\ t \end{bmatrix} \in \Col_2
        </me>.
        Now consider
        <me>
          f(x) = \frac{2s}{\pi}\cos(x) + \frac{2t}{\pi}\sin(x)
        </me>.
        Using the table of integrals above, we see that
        <me>
          S(T) = \begin{bmatrix} s \\ t \end{bmatrix} .
        </me>
        Hence <me>
        \Rank(T) = 2
        </me>.
      </p>

      <p>
        Since <m>\Dim(\Trig_2) = 5</m>, the Rank-Nullity theorem is verified for <m>S</m>.
      </p>
    </solution>
  </exercise>

  <exercise>
    <statement>
      <p>
        The <q>curl</q> map
        <md>
          <mrow> C : \Vect_2(\mathbb{R}^2) \amp \rightarrow \Poly_1[x,y]</mrow>
          <mrow> (P,Q) \amp \mapsto \frac{\partial Q}{\partial y} - \frac{\partial P}{\partial x}</mrow>
        </md>
        Bonus question: What kind of vector fields live in the kernel of <m>C</m>?
      </p>
    </statement>
  </exercise>

  <exercise xml:id="exercise-RankNullity-group-last">
    <statement>
      <p>(Poole 6.5.12) The map
        <md>
          <mrow>T : \Mat_{2,2} \amp \rightarrow \Mat_{2,2} </mrow>
          <mrow> \mat{A} \amp \mapsto \mat{A} \mat{B} - \mat{B} \mat{A}</mrow>
        </md>
        where
        <me>
          \mat{B} = \begin{bmatrix} 1 \amp -1 \\ -1 \amp 1 \end{bmatrix}
        </me>
      </p>
    </statement>
  </exercise>
</exercisegroup>

  <exercise>
    <statement>
      <p>
        Give an example of a linear map
        <m>T : \Col_4 \rightarrow \Col_4</m> such that <m>\Rank(T) = \Nullity(T)</m>.
      </p>
    </statement>
    <solution>
      <p>
        Define <m> T </m> by
        <me>
          T: \begin{bmatrix} x\\y\\z\\w\end{bmatrix} \mapsto \begin{bmatrix} x\\y\\0\\0\end{bmatrix}
        </me>
        <me>
          \Ker(T) = \left\{\begin{bmatrix} 0\\0\\z\\w\end{bmatrix} \in \Col_4 \right\}
        </me>
        and
        <me>
          \Im(T) = \left\{\begin{bmatrix} x\\y\\0\\0\end{bmatrix} \in \Col_4 \right\}
        </me>.
        Both <m>\Ker(T)</m> and <m>\Im(T)</m> are isomorphic to <m>\Col_2</m> and hence
        <me>
          \Rank(T) = \Nullity(2) = 2
        </me>.
      </p>
    </solution>
  </exercise>

  <exercise>
    <statement>
      <p>
        For each of the following assertions,
        state whether it is <em>true</em> or <em>false</em>.
        If it is true, prove it.
        If it is false, prove that it is false.

        <ol label="(a)">
          <li>
            <p>
              There exists a linear map <m>T : \mathbb{R}^5 \rightarrow \mathbb{R}^2</m> such that
              <me>
                \Ker(T) = \{ (x_1, x_2, x_3, x_4, x_5) \in \mathbb{R}^5 : x_1 = 3x_2 \text{ and }  x_3 = x_4 = x_5\}
              </me>.
            </p>
          </li>

          <li>
            <p>
              There exists a linear map
              <m>F : \Trig_3 \rightarrow \Trig_3</m> such that <m>\Rank(T) = \Nullity(T)</m>.
            </p>
          </li>
        </ol>
      </p>
    </statement>
    <solution>
     <p>
        <ol label="(a)">
          <li>
            <p>
             The statement is false. To see this, notice that if such a map were to exist then its kernel would be 2-dimensional since any choice of <m> x_1</m> and <m>x_3 </m> uniquely determines an element in <m>\Ker(T)</m>. But then by the Rank-Nullity theorem, <m> \Rank(T) = 3 </m> since <m> \mathbb R^5 </m> is 5 dimensional. But <m>\Im(T)</m> is a subspace of <m>\mathbb R^2</m> <mdash/> which is absurd, since <m> \mathbb R^2 </m> itself is 2-dimensional.
            </p>
          </li>

          <li>
            <p>
              The statement is false. Suppose such a map were to exist. Recall that <m> \Dim(\Trig_3) = 7</m>. Then by the Rank-Nullity theorem,
              <me>
              7 = \Rank(T) + \Nullity(T) = 2\Rank(T).
            </me>
            But 7 is odd, so we have a contradiction! Thus no such map can exist.
            </p>
          </li>
        </ol>
      </p>
    </solution>
  </exercise>

  <exercise>
    <statement>
      <p>
        Let <m>f(x,y,z)</m> be a function on
        <m>\mathbb{R}^3</m> and fix a point <m>\ve{p} = (x_0, y_0, z_0) \in \mathbb{R}^3</m>.
        For each vector <m>\ve{u} \in \mathbb{R}^3</m>,
        we can regard the derivative of <m>f</m> in the direction of <m>\ve{u}</m> at <m>\ve{p}</m> as a map
        <md>
          <mrow>D_{\ve{p}} : \mathbb{R}^3 \amp \rightarrow \mathbb{R}</mrow>
          <mrow>\ve{u} \amp \mapsto (\nabla f)(\ve{p}) \cdot \ve{u}</mrow>
        </md>.

        <ol label="(a)">
          <li>
            <p>
              Show that <m>D_{\ve{p}}</m> as defined above is a linear map.
            </p>
          </li>

          <li>
            <p>
              Consider the example of <m>f(x,y,z) = x^2 + y^2 + z^2</m>.
              Determine <m>\Ker(D_\ve{p})</m> for all points <m>\ve{p} \in \mathbb{R}^3</m>.
            </p>
          </li>
        </ol>
      </p>
    </statement>
    <solution>
      <p>
        <ol label="(a)">

          <li>
            <p>
              The fact that <m>D_\ve{p}</m> is a linear map follows from the usual properties of the dot product:
              <md>
                <mrow> D_\ve{p}(\ve u + \ve v) \amp = \begin{bmatrix} \frac{\partial f}{\partial x}(\ve p)\\ \frac{\partial f}{\partial y}(\ve p) \\ \frac{\partial f}{\partial z}(\ve p) \end{bmatrix} \cdot (\ve u + \ve v) </mrow>
                <mrow>\amp  = \begin{bmatrix} \frac{\partial f}{\partial x}(\ve p)\\ \frac{\partial f}{\partial y}(\ve p) \\ \frac{\partial f}{\partial z}(\ve p) \end{bmatrix} \cdot \ve u + \begin{bmatrix} \frac{\partial f}{\partial x}(\ve p)\\ \frac{\partial f}{\partial y}(\ve p) \\ \frac{\partial f}{\partial z}(\ve p) \end{bmatrix} \cdot \ve v  </mrow>
                <mrow>\amp = D_\ve{p}(\ve u) + D_\ve{p}(\ve v) </mrow>
              </md>.
              Similarly,
              <md>
                <mrow> D_\ve{p}(k\ve u) \amp = \begin{bmatrix} \frac{\partial f}{\partial x}(\ve p)\\ \frac{\partial f}{\partial y}(\ve p) \\ \frac{\partial f}{\partial z}(\ve p) \end{bmatrix} \cdot \ve ku</mrow>
                <mrow> \amp =\begin{bmatrix} k\frac{\partial f}{\partial x}(\ve p)\\ k\frac{\partial f}{\partial y}(\ve p) \\k \frac{\partial f}{\partial z}(\ve p) \end{bmatrix} \cdot \ve u </mrow>
                <mrow> \amp = k \begin{bmatrix} \frac{\partial f}{\partial x}(\ve p)\\ \frac{\partial f}{\partial y}(\ve p) \\ \frac{\partial f}{\partial z}(\ve p) \end{bmatrix} \cdot \ve u</mrow>
                <mrow> \amp = k D_\ve{p} \cdot \ve u</mrow>
              </md>.
              And so <m>D_\ve{p}</m> is linear.
            </p>
          </li>

          <li>
            <p>
              <m> \ve u = (x_1,y_1,z_1) \in \Ker(D_\ve{p}) </m> if and only if
              <mdn>
                <mrow> \amp D_\ve{p}(\ve u ) = 0</mrow>
                <mrow>\iff \amp \left( \frac{\partial f}{\partial x}(\ve p) , \frac{\partial f}{\partial y}(\ve p) , \frac{\partial f}{\partial z}(\ve p)\right) \cdot (u_0,u_1,u_2) = 0 </mrow>
                <mrow>\iff \amp 2x_0x_1 + 2y_0y_1 + 2z_0z_1 = 0</mrow>
            </mdn>.
            Geometrically, <m>\Ker(D_\ve{p}</m> consists of all vectors <m>\ve v</m> that lie tangent to a circle of radius <m>|\ve p |</m> centred at the origin at the point <m>\ve p </m>.
            </p>
          </li>
        </ol>
      </p>
    </solution>
  </exercise>

  <exercise>
    <statement>
      <p>
        Using the Rank-Nullity theorem,
        give a different proof of the fact that the image of the map <m>C</m> in
        <xref ref="cross-product-example">Example</xref>
        is <m>\{ \ve{u} \in \mathbb{R}^3 : \ve{u} \cdot \ve{a} = 0 \}</m>.
      </p>
    </statement>
    <solution>
      <p>
        For reference, we reproduce a portion of the proof in <xref ref="cross-product-example">Example</xref>:
      </p>

      <blockquote>
      <p>
        The kernel of <m>C</m> is the subspace of
        <m>\mathbb{R}^3</m> consisting of all vectors
        <m>\ve{v} \in V</m> such that <m>\ve{a} \times \ve{v} = \ve{0}</m>.
        From the geometric formula for the cross-product,
        <me>
          |\ve{a} \times \ve{v}| = |\ve{a}| |\ve{v}| \sin \theta
        </me>
        where <m>\theta</m> is the angle from <m>\ve{a}</m> to <m>\ve{\theta}</m>,
        we see that
        <me>
          \ve{a} \times \ve{v} = \ve{0}  \Leftrightarrow \ve{v}=\ve{0}\text{ or }\theta = 0\text{ or }\theta= \pi
        </me>.
      </p>

      <p>
        In other words,
        <m>\ve{v}</m> must be a scalar multiple of <m>\ve{a}</m>.
        So,
        <me>
          \Ker(C) = \{ k \ve{a}, k \in \mathbb{R} \}
        </me>.
      </p>

      <p>
        I claim that the <em>image</em>
        of <m>C</m> is the subspace of <em>all</em>
        vectors perpendicular to <m>\ve{a}</m>, i.e.
        <men>
          \Im(C) := \{ \ve{u} \in \mathbb{R}^3 : \ve{u} \dotp \ve{a} = 0 \}
        </men>.
      </p>

      <p>
        If you believe me, then the picture is as follows:
      </p>
<!--  This image should already be elsewhere - maybe link to it to for a knowl? (Can't have an image inside a blockquote!)
      <figure>
        <caption></caption>
        <image>
          <latex-image>
            <![CDATA[\begin{tikzpicture}\draw (0,0) - - (1,2) - - (3,2) - - (2,0) - - (0,0);
            \draw (1.5, 1) - - (1.5,3.5) node[right] {\(\Ker{C}\)};
            \draw (1.5, -0.1) - - (1.5, -2);
            \node at (3.3, 1) {\(\Im(C)\)};
            \draw[very thick, red, ->] (1.5,1) - - (1.5, 2.5) node[right] {\(\ve{a}\)};\end{tikzpicture}]]>
          </latex-image>
        </image>
      </figure>
-->
      <p>
        Let me prove equation <xref ref="image-of-C" />.
        By definition, the image of <m>C</m> is the subspace of
        <m>\mathbb{R}^3</m> consisting of all vectors <m>\ve{w}</m> of the form
        <m>\ve{w} = \ve{a} \times \ve{v}</m> for some <m>\ve{v} \in \mathbb{R}^3</m>.
        This implies that <m>\ve{w}</m> is perpendicular to <m>\ve{a}</m>.
      </p>
    </blockquote>
      <p>
        And thus we know that
        <me>
          \Im(C) \subset \{ \ve{u} \in \mathbb{R}^3 : \ve{u} \dotp \ve{a} = 0 \}
        </me>.
        We shall use the Rank-Nullity theorem to show the converse in a fantastically succint way. By the Rank-Nullity theorem
        <md>
          <mrow> \amp \Dim(\mathbb R^3)  = \Nullity(C) + \Rank(C)</mrow>
          <mrow>\implies \amp 3 = 1 + \Rank(C).</mrow>
        </md>
        And so we also know the <m> \Im(C) </m> is a 2-dimensional subspace of <m>\mathbb R^3 </m>. Of course,
        <me>
         \{ \ve{u} \in \mathbb{R}^3 : \ve{u} \dotp \ve{a} = 0 \}
        </me>
        is also 2-dimensional. But now, if one 2-dimensional subspace is contained in another 2-dimensional subspace then the two subspaces must necessarily be <em>the same</em>! Hence
        <me>
          \Im(C) = \{ \ve{u} \in \mathbb{R}^3 : \ve{u} \dotp \ve{a} = 0 \}
        </me>
      </p>
      <p>
        (By using the Rank-Nullity theorem, we managed to bypass the trickest part of <xref ref="cross-product-example"/>!)
      </p>
  </solution>
  </exercise>

  <exercise>
    <statement>
      <p>
        Determine the kernel and image of the linear map
        <me>
          T : \Poly_2[x,y,z] \rightarrow \Poly_2
        </me>
        defined by
        <me>
          T(p)(x) := p(x,x,x)
        </me>.
      </p>
    </statement>
  </exercise>


 <exercise>
    <statement>
      <p>
        Let <m>V</m> be a finite-dimensional vector space. Let <m>U</m> be a subspace of <m>V</m>. Show that there exists a linear map <m>T: V \to V</m> such that <m>\Ker T = U</m>.
      </p>
    </statement>
    <solution>
      <p>
        To do.
      </p>
    </solution>
  </exercise>

  <exercise>
    <statement>
      <p>
        Consider the function <m>F:\R^2 \to \R^2</m> defined by
        <me>
          F(x,y)=(x^2 + y^2, xy).
        </me>
        Consider now the <m>DF_p</m>, the Jacobian matrix of <m>F</m> at the point <m>p = (1,2)</m>. Find <m>\Ker (DF_p)</m> and <m>\Im (DF_p)</m> and subsequently find <m>\Nullity(DF_p)</m> and <m>\Rank(DF_p)</m>.
      </p>
    </statement>
    <solution>
      <p>
      </p>
    </solution>
  </exercise>

  <exercise>
    <statement>
      <p>
        Let <m>T:U\to V</m> and <m>S:V\to W</m> be two linear maps. Show that if <m>Im(T)</m> is a subspace of <m>Ker(S)</m>, then the composite map <m>S\circ T</m> is the zero map (i.e. it maps every input vector of <m>U</m> to the zero vector in <m>W</m>).
      </p>
    </statement>
    <solution>
      <p>
        Let <m>u\in U</m> be any vector. Then <m>T(u)</m> is an element of <m>Im(T)</m>, by the definition of <m>Im(T)</m>. But since <m>Im(T)\subset Ker(S)</m> any element of <m>Im(T)</m> is an element of <m>Ker(S)</m>. In particular, <m>T(u)\in Ker(S)</m>. But this is equivalent to saying that <m>S(T(u))=0</m>. Thus the composite map <m>S\circ T</m> maps every <m>u\in U</m> to the zero vector in <m>W</m>.
      </p>
    </solution>
  </exercise>

  <exercise>
    <statement>
      <p>
        Let <m>T:U\to V</m> and <m>S:V\to W</m> be two linear maps. Show that <m>Ker(T)</m> is a subspace of <m>Ker(S\circ T)</m>. Is it possible for <m>Ker(S\circ T)</m> to be strictly larger?
      </p>
    </statement>
    <solution>
      <p>
        To show that <m>Ker(T)\subset Ker(S\circ T)</m> we need to show that if <m>u\in Ker(T)</m>, then <m>u\in Ker(S\circ T)</m>. So assume that <m>u\in Ker(T)</m>, which means that <m>T(u)=0_V</m>. Then <m>S(T(u)) = S(0_V) = 0_W</m>, which is the same as saying that <m>u\in Ker (S\circ T)</m>.
      </p>
      <p>
        It is possible for <m>\Ker(S\circ T)</m> to be strictly larger than <m>Ker(T)</m>. The simplest example is the extreme case where <m>T</m> is the identity map on <m>U=V</m> and <m>S</m> is the zero map to any vector space. Then the kernel of <m>T</m> contains only the zero vector, but the kernel of <m>S\circ T</m> contains all the vectors in <m>V</m>. So, actually for this to be a valid example, we need to specify that <m>V</m> is not the zero vector space.
      </p>
    </solution>
  </exercise>

</exercises>

</section>

