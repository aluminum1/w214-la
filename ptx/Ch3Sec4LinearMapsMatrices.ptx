

<section xml:id="Ch3Sec4LinearMapsMatrices">
  <title>Linear maps and matrices</title>

  <objectives>
    <ul>
      <li>Find a way to represent a linear map efficiently.</li>
      <li>Find relations between the matrices associated to composites and inverses of linear maps.</li>
    </ul>
  </objectives>

  <definition xml:id="matrix_of_linear_map_defn">
    <statement>
      <p>
        Let <m>T : V \rightarrow W</m> be a linear map from a vector space <m>V</m> to a vector space <m>W</m>.
        Let <m>\basis{B} = \bopen \ve{b}_1, \ldots, \ve{b}_m \bclose</m> be a basis for <m>V</m> and
        <m>\basis{C} = \bopen \ve{c}_1, \ldots, \ve{c}_n \bclose</m> be a basis for <m>W</m>.
        The <term>matrix of <m>T</m> with respect to the bases
        <m>\basis{B}</m> and <m>\basis{C}</m></term>
        is defined as the <m>n \times m</m> matrix whose columns are the coordinate vectors of
        <m>T(\ve{b}_i)</m> with respect to the basis <m>\basis{C}</m>:
        <me>
          [T]_{\basis{C} \leftarrow \basis{B}} :=
          \begin{bmatrix} \left[\begin{array}{c} \, \\ T(\ve b_1) \\ \, \end{array}\right]_\basis{C} \amp \left[\begin{array}{c} \,\\ T(\ve b_2)  \\ \, \end{array}\right]_\basis{C} \amp \ldots \amp \left[\begin{array}{c} \, \\ T(\ve b_m) \\ \,\end{array}\right]_\basis{C}  \end{bmatrix}
        </me>
      </p>
    </statement>
  </definition>

  <exercise>
    <p>
      Why is <m>[T]_{\basis{C} \leftarrow \basis{B}}</m> an <m>n \times m</m> matrix?
    </p>
  </exercise>

  <insight>
    <p>
      In the case of a linear operator <m>T:V\to V</m>,
      it is possible to choose two different bases <m>\basis B</m> and <m>\basis C</m> for the same vector space
      (see <xref ref="change-of-basis-as-matrix"/> for example);
      and <xref ref="matrix_of_linear_map_defn"/> will still make sense.
      However, it is possible (and most common; see <xref ref="matrix-in-different-basis"/> for example) to use the same basis for <m>V</m> as domain and codomain.
      If <m>V</m> and <m>W</m> are not the same space, then of course <m>\basis B</m> and <m>\basis C</m> cannot be the same!
    </p>
  </insight>

  <example xml:id="first_example_matrix_lin_map">
    <title>
      Matrix of a Linear Map
    </title>
    <statement>
      <p>
        Let
        <me>
          T : \Poly_2 \rightarrow \Poly_3
        </me>
        be defined by
        <me>
          T(p)(x) := x p(x)
        </me>
        Let
        <me>
          \basis{B} = \bopen b_1 = 1+x, b_2 = 1-x, b_3 = 1+x+x^2 \bclose
        </me>
        and
        <me>
          \basis{C} = \bopen c_1 = 1, c_2 = 1+x, c_3 = 1+x+x^2, c_4 = x^3 \bclose
        </me>
        be bases for <m>\Poly_2</m> and <m>\Poly_3</m> respectively. Determine <m>[T]_{\basis{C} \leftarrow \basis{B}}</m>.
      </p>
    </statement>
    <solution>
      <p>
        We compute:
        <md>
          <mrow>
            T(b_1) \amp = x(1+x)
          </mrow>
          <mrow>
            \amp = x + x^2
          </mrow>
          <mrow>
            \amp = -c_1 + c_3
          </mrow>
          <mrow>
            \therefore [T(b_1)]_{\basis{C}} \amp = \begin{bmatrix} -1 \\ 0 \\ 1 \\ 0 \end{bmatrix}
          </mrow>
          <mrow>
            T(b_2) \amp = x (1-x)
          </mrow>
          <mrow>
            \amp = x - x^2
          </mrow>
          <mrow>
            \amp = -c_1 + 2c_2 - c_3
          </mrow>
          <mrow>
            \therefore [T(b_2)]_{\basis{C}} \amp =
            \begin{bmatrix} -1 \\ 2 \\ -1 \\ 0 \end{bmatrix}
          </mrow>
          <mrow>
            T(b_3) \amp = x(1+x+x^2)
          </mrow>
          <mrow> \amp = x + x^2 + x^3 </mrow>
          <mrow> \amp = -c_1 + c_3 +c_4 </mrow>
          <mrow> \therefore [T(b_3)]_{\basis{C}} \amp =
            \begin{bmatrix} -1 \\ 0 \\ 1 \\ 1 \end{bmatrix}</mrow>
        </md>
        Assembling all these coordinate vectors together gives
        <me>
          [T]_{\basis{C} \leftarrow \basis{B}} =
          \begin{bmatrix}
            -1 \amp -1 \amp -1 \\
            0 \amp 2 \amp 0 \\
            1 \amp -1 \amp 1 \\
            0 \amp 0 \amp 1
          \end{bmatrix}
        </me>
      </p>
    </solution>
  </example>

  <theorem xml:id="lin-map-in-matrix-theorem">
    <title>Linear maps and matrix multiplication of coordinate vectors</title>
    <statement>
      <p>
        Let <m>T : V \rightarrow W</m> be a linear map from a vector space <m>V</m> to a vector space <m>W</m>.
        Let <m>\basis{B} = \bopen \ve{b}_1, \ldots, \ve{b}_m \bclose</m> be a basis for <m>V</m> and
        <m>\basis{C}</m> be a basis for <m>W</m>.
        Then for all vectors <m>\ve{v}</m> in <m>V</m>,
        <men xml:id="lin-maps-and-matrices-eqn">
          [T(\ve{v})]_\basis{C} = [T]_{\basis{C} \leftarrow \basis{B}} [\ve{v}]_\basis{B}
        </men>
        where the right hand side is the product of the matrix
        <m>[T]_{\basis{C} \leftarrow \basis{B}}</m> with the coordinate vector <m>[\ve{v}]_\basis{B}</m>.
      </p>
    </statement>

    <proof>
      <p>
        Similar to the proof of the Change-Of-Basis Theorem
        (<xref ref="change-of-basis-thm">Theorem</xref>).
        Let <m>\ve{v} \in V</m>.
        Expand it in the basis <m>\basis{B}</m>:
        <me>
          \ve{v} = a_1 \ve{b}_1 + a_2 \ve{b}_2 + \cdots + a_m \ve{b}_m,  \text{i.e. }  [\ve{v}]_\basis{B} = \begin{bmatrix}a_1 \\ \vdots \\ a_m \end{bmatrix}
        </me>.
      </p>

      <p>
        Then,
        <md>
          <mrow>[\ve{v}]_\basis{C} \amp = [T(a_1 \ve{b}_1 + \cdots + a_m \ve{b}_m)]_\basis{C}</mrow>
          <mrow>\amp = [a_1 T(\ve{b}_1) + \cdots + a_n T(\ve{b}_m)]_\basis{C} \amp \amp  (T \text{ is linear)}</mrow>
          <mrow>\amp = a_1 [T(\ve{b}_1)]_\basis{C} + \cdots + a_n [T(\ve{b}_m)]_\basis{C}  \amp \amp  (<xref ref = "lin_of_coord_vectors" />)</mrow>
         <mrow> \amp =  \begin{bmatrix} \bigg[ T(\ve b_1) \bigg]_\basis{C} \amp \bigg[T(\ve b_2) \bigg]_\basis{C} \amp \cdots \amp \bigg[ T(\ve b_m) \bigg]_\basis{C}  \end{bmatrix} \begin{bmatrix}a_1 \\ \vdots \\ a_m \end{bmatrix} </mrow>
          <mrow>\amp =    [T]_{\basis{C} \leftarrow \basis{B}} [\ve{v}]_\basis{B} \, </mrow>
        </md>.
      </p>
    </proof>
  </theorem>

  <example>
    <title>Verifying <xref ref="lin-map-in-matrix-theorem"/> in an example</title>
    <statement>
      <p>
        Let us verify that <xref ref="lin-map-in-matrix-theorem"/> really works, in the context of <xref ref="first_example_matrix_lin_map"/>. Let us take the vector <m>\ve{v} \in \Poly_2</m> to be, for instance, <m>x</m>.
      </p>
      <p>
        Exapnding <m>x</m> relative to the basis <m>\basis{B}</m>, we get
        <me>
          x = \frac{1}{2} (p_1 - p_2).
        </me>
        So,
        <me>
          [x]_{\basis{B}} = \begin{bmatrix} \frac{1}{2} \\ - \frac{1}{2} \\ 0 \end{bmatrix}
        </me>
        Also, <m>T(x) = x^2 = -q_2 + q_3</m>, so
        <me>
          [T(x)]_{\basis{C}} = \begin{bmatrix} 0 \\ -1 \\ 1 \\ 0 \end{bmatrix}
        </me>
        We can now compute the left and right hand sides of Equation <xref ref="lin-maps-and-matrices-eqn"/> and see that they are indeed the same.
        <md>
          <mrow>\text{LHS of } <xref ref="lin-maps-and-matrices-eqn"/> \amp = [T(x)]_{\basis{C}} </mrow>
          <mrow> \amp =  \begin{bmatrix} 0 \\ -1 \\ 1 \\ 0 \end{bmatrix}. </mrow>
          <mrow>\text{RHS of }<xref ref="lin-maps-and-matrices-eqn"/> \amp = [T]_{\basis{C} \leftarrow \basis{B}} [x]_{\basis{B}}   </mrow>
          <mrow> \amp= \begin{bmatrix}  -1 \amp -1 \amp -1 \\ 0 \amp 2 \amp 0 \\ 1 \amp -1 \amp 1 \\ 0 \amp 0 \amp 1 \end{bmatrix} \begin{bmatrix} \frac{1}{2} \\ -\frac{1}{2} \\ 0 \end{bmatrix} </mrow>
          <mrow> \amp = \begin{bmatrix} 0 \\ -1 \\ 1 \\ 0 \end{bmatrix}</mrow>
        </md>
        So the Theorem indeed works, at least in this case!
      </p>
    </statement>
  </example>

  <p>
    We can interpret <xref ref="lin-map-in-matrix-theorem">Theorem</xref>
    in a more abstract way as follows.
    We have the following diagram of linear maps of vector spaces:
  </p>

  <figure>
    <caption>Visual representation of <xref ref="lin-map-in-matrix-theorem"/></caption>
    <image width="80%">
      <latex-image>
        <![CDATA[\begin{tikzpicture}[yscale=0.8]
        \draw (0, 0) circle (1);
        \draw (6,0) circle (1);
        \draw [<->] (-1, -6) -- (1, -6);
        \draw [<->] (0, -5) -- (0, -7);
        \draw [<->] (5, -6) -- (7, -6);
        \draw [<->] (6, -5) -- (6, -7);
        \draw[->] (2, 0) -- node[above]{\(T\)} (4, 0);
        \draw[->] (6, -2) -- node[right] {\([ \smul]_\basis{C}\)} (6, -4);
        \draw[->, dotted] (2, -6) -- node[below] {\([\cdot]_\basis{C} \circ T \circ \ve{vec}_{V, \basis{B}}\)} (4, -6);
        \draw[->] (-0.1, -2) -- node[left] {\([ \smul]_\basis{B}\)} (-0.1, -4);
        \draw[<-] (0.1, -2) -- node[right] {\(\ve{vec}_{V, \basis{B}}\)} (0.1, -4);
        \node at (1, 1) {\(V\)};
        \node at (7, 1) {\(W\)};
        \node at (1, -5) {\(\Col_m\)};
        \node at (7, -5) {\(\Col_n\)};\end{tikzpicture}]]>
      </latex-image>
    </image>
  </figure>

  <p>
    The map at the top is the linear map <m>T : V \rightarrow W</m>.
    The map on the left from <m>V</m> to <m>\Col_m</m> is the coordinate vector map
    <m>[ \smul]_\basis{B}</m> associated to the basis <m>\basis{B}</m>.
    Its inverse map <m>\ve{vec}_{V, \basis{B}} : \Col_m \rightarrow V</m> is also drawn.
    The map on the right is the coordinate vector map
    <m>[ \cdot]_\basis{C}</m> from <m>W</m> to <m>\Col_n</m> associated to the basis <m>C</m>.
    The dotted arrow on the bottom is the composite map,
    and can be computed explicitly as follows.
  </p>

  <lemma>
    <statement>
      <p>
        The composite map
        <me>
          [\cdot]_\basis{C} \circ T \circ \ve{vec}_{V, \basis{B}} : \Col_m \rightarrow \Col_n
        </me>
        is multiplication by the matrix <m>[T]_{\basis{C} \leftarrow \basis{B}}</m>.
        That is, for all column vectors <m>\mat{u}</m> in <m>\Col_m</m>,
        <me>
          \left( [\cdot]_\basis{C} \circ T \circ \ve{vec}_{V, \basis{B}} \right) (\mat{u}) = [T]_{\basis{C} \leftarrow \basis{B}} \, \mat{u}
        </me>.
      </p>
    </statement>
  </lemma>

  <proof>
    <p>
      Let <m>\mat{u}</m> be a column vector in <m>\Col_m</m>.
      Define <m>\ve{v} := \ve{vec}_{V, \basis{B}} (\mat{u})</m>.
      Then <m>\ve{v}</m> is the vector in <m>V</m> whose coordinate vector with respect to the basis <m>\basis{B}</m> is <m>\mat{u}</m>.
      That is, <m>\mat{u} = [\ve{v}]_\basis{B}</m>.
      So,
      <md>
        <mrow>\left( [\cdot]_\basis{C} \circ T \circ \ve{vec}_{V, \basis{B}} \right) (\mat{u})  \amp = [ \smul]_\basis{C} \left( T \left(\ve{vec}_{V, \basis{B}}(\mat{u})\right)\right) \amp \amp  \text{(Defn of composite map)}</mrow>
        <mrow>\amp = [\cdot]_\basis{C} (T(\ve{v})) \amp \amp  \text{(Defn of } \ve{v})</mrow>
        <mrow>\amp = [T(\ve{v})]_\basis{C} \amp \amp  \text{(Defn of } [\cdot]_\basis{C})</mrow>
        <mrow>\amp = [T]_{\basis{C} \leftarrow \basis{B}} [\ve{v}]_\basis{B} \amp \amp(<xref ref = "lin-map-in-matrix-theorem" />)  </mrow>
      </md>.
    </p>
  </proof>

  <p>
    Before we move on, we need to recall another thing about matrices.
    Suppose <m>\mat{A}</m> is a matrix with <m>n</m> rows.
    Let
    <me>
      \mat{e}_1 = \begin{bmatrix}1 \\ 0 \\ \vdots \\ 0\end{bmatrix}, \, \mat{e}_2 = \begin{bmatrix}0 \\ 1 \\ \vdots \\ 0\end{bmatrix}, \, \ldots, \, \mat{e}_n = \begin{bmatrix}0 \\ 0 \\ \vdots \\ 1 \end{bmatrix}
    </me>
    be the standard basis for <m>\Col_n</m>.
    Then the <m>i</m>th column of <m>A</m> can be obtained by multiplying <m>A</m> with <m>\mat{e}_i</m>:
    <men xml:id="fact-about-columns">
      i^\text{th} \text{ column of } \mat A  = A \mat{e}_i
    </men>.
  </p>

  <exercise xml:id="fact_about_columns_of_matrix">
    <statement>
      <p>
        Check <xref ref="fact-about-columns" />!
      </p>
    </statement>
  </exercise>

  <p>
    Now we can prove the following important Theorem.
  </p>

  <theorem xml:id="functoriality_of_matrix">
    <title>Functoriality of the Matrix of a Linear Map</title>
    <statement>
      <p>
        Let <m>S : U \rightarrow V</m> and
        <m>T : V \rightarrow W</m> be linear maps between finite-dimensional vector spaces.
        Let <m>\basis{B}</m>, <m>\basis{C}</m> and
        <m>\basis{D}</m> be bases for <m>U</m>,
        <m>V</m> and <m>W</m> respectively.
        Then
        <me>
          [T \circ S]_{\basis{D} \leftarrow \basis{B}} = [T]_{\basis{D} \leftarrow \basis{C}} [S]_{\basis{C} \leftarrow \basis{B}}
        </me>,
        where the right hand side is the product of the matrices
        <m>[T]_{\basis{D} \leftarrow \basis{C}}</m> and <m>[S]_{\basis{C} \leftarrow \basis{B}}</m>.
      </p>
    </statement>
  </theorem>

  <proof>
    <p>
      We have:
      <md>
        <mrow>i\text{-th colu} \amp \text{mn of } [T \circ S]_{\basis{D} \leftarrow \basis{B}}</mrow>
        <mrow>\amp = \left[(T \circ S)(\ve{b}_i)\right]_\basis{D} \amp \amp  \text{(Defn of }[T \circ S]_{\basis{D} \leftarrow \basis{B}})</mrow>
        <mrow>\amp = \left[T(S(\ve{b}_i))\right]_\basis{D} \amp \amp  \text{(Defn of } T \circ S )</mrow>
        <mrow>\amp = [T]_{\basis{D} \leftarrow \basis{C}} \, [S(\ve{b}_i]_\basis{C} \amp \amp  (<xref ref = "lin-map-in-matrix-theorem"/>)</mrow>
        <mrow>\amp = [T]_{\basis{D} \leftarrow \basis{C}} \, [S]_{\basis{C} \leftarrow \basis{B}} \, [\ve{b}_i]_\basis{B} \amp \amp  (<xref ref = "lin-map-in-matrix-theorem"/>)</mrow>
        <mrow>\amp = [T]_{\basis{D} \leftarrow \basis{C}} \, [S]_{\basis{C} \leftarrow \basis{B}} \, \mat{e}_i \amp \amp  \left(\text{since }
        [\ve{b}_i]_\basis{B} = \mat{e}_i
        \right)</mrow>
        <mrow>\amp = i\text{-th column of } [T]_{\basis{D} \leftarrow \basis{C}} [S]_{\basis{C} \leftarrow \basis{B}}  \amp \amp  <xref ref = "fact-about-columns"/> </mrow>
      </md>.
    </p>
  </proof>

  <corollary xml:id="map-iso-matrix-iso">
    <statement>
      <p>
        Let <m>T : V \rightarrow W</m> be a linear map,
        and suppose <m>\basis{B}</m> is a basis for <m>V</m>,
        and <m>\basis{C}</m> is a basis for <m>W</m>.
        Then
        <me>
          (T \text{ is an isomorphism})  \Longleftrightarrow [T]_{\basis{C} \leftarrow \basis{B}} \text{ is invertible}
        </me>.
      </p>
    </statement>
  </corollary>

  <proof>
  <case direction="forward">
    <p>
      Suppose the linear map <m>T</m> is an isomorphism.
      This means there exists a linear map <m>S : W \rightarrow V</m> such that
      <me>
        S \circ T = \id_V  \text{ and }   T \circ S = \id_W
      </me>
    </p>

    <p>
      Therefore,
      <me>
        [S \circ T]_{\basis{B} \leftarrow \basis{B}} = [\id_V]_{\basis{B} \leftarrow \basis{B}}  \text{ and }   [T \circ S]_{\basis{C} \leftarrow \basis{C}} = [\id_W]_{\basis{C} \leftarrow \basis{C}}
      </me>.
    </p>

    <p>
      Therefore, by the Functoriality of the Matrix of a Linear Map (<xref ref="functoriality_of_matrix">Theorem</xref>),
      <me>
        [S]_{\basis{B} \leftarrow \basis{C}} [T]_{\basis{C} \leftarrow \basis{B}} = I  \text{ and }   [T]_{\basis{C} \leftarrow \basis{B}} [S]_{\basis{B} \leftarrow \basis{C}} = I
      </me>
    </p>

    <p>
      Therefore the matrix <m>[T]_{\basis{C} \leftarrow \basis{B}}</m> is invertible,
      with inverse given by
      <me>
        [T]^{-1}_{\basis{C} \leftarrow \basis{B}} = [S]_{\basis{B} \leftarrow \basis{C}}
      </me>.
    </p>
  </case>

  <case direction="backward">
    <p>
      Suppose the matrix <m>[T] \equiv [T]_{\basis{C} \leftarrow \basis{B}}</m> is invertible.
      Define the linear map
      <me>
        S : W \rightarrow V
      </me>
      by firstly defining it on the basis vectors in <m>\basis{C}</m> by
      <me>
        S(\ve{c}_i) := \sum_{p=1}^{\Dim V} [T]^{-1}_{pi} \ve{b}_p
      </me>
      and then extending to all of <m>W</m> by linearity.
      Then we have
      <md>
        <mrow>(T \circ S)(\ve{c}_i) \amp = T(S(\ve{c}_i))</mrow>
        <mrow>\amp = T\left( \sum_{p=1}^{\Dim V} [T]_{pi}^{-1} \ve{b}_p \right)</mrow>
        <mrow>\amp = \sum_{p=1}^{\Dim V} \sum_{q=1}^{\Dim W} [T]^{-1}_{pi} [T]_{qp} \ve{c}_q</mrow>
        <mrow>\amp = \sum_{q=1}^{\Dim W} \left( \sum_{p=1}^{\Dim V} [T]_{qp} [T]^{-1}_{pi} \right) \ve{c}_q</mrow>
        <mrow>\amp = \sum_{q=1}^{\Dim W} \left( [T] [T]^{-1} \right)_{qi} \ve{c}_q</mrow>
        <mrow>\amp = \sum_{q=1}^{\Dim W} I_{qi} \ve{c}_q</mrow>
        <mrow>\amp = \sum_{q=1}^{\Dim W} \delta_{qi} \ve{c}_q</mrow>
        <mrow>\amp = \ve{c_i}</mrow>
      </md>.
    </p>

    <p>
      Therefore, <m>T \circ S = \id_W</m>.
      In a similar way, we can prove that <m>S \circ T = \id_V</m>.
      Therefore the linear map <m>T</m> is an isomorphism,
      with inverse map <m>T^{-1} = S</m>.
    </p>
  </case>
  </proof>

  <p>
    We can refine this a bit further.
    Explicitly, <q>the inverse of the matrix of a linear map equals the matrix of the inverse of the linear map</q>.
  </p>

  <corollary xml:id="inverse-of-map-via-matrices">
    <statement>
      <p>
        Suppose <m>\basis{B}</m> and
        <m>\basis{C}</m> are bases for vector spaces <m>V</m> and <m>W</m> respectively.
        Suppose a linear map <m>T : V \rightarrow W</m> has inverse <m>T^{-1} : W \rightarrow V</m>.
        Then
        <me>
          [T]_{\basis{C} \leftarrow \basis{B}}^{-1} = [T^{-1}]_{\basis{B} \leftarrow \basis{C}}
        </me>.
      </p>
    </statement>
  </corollary>

  <proof>
    <p>
      We have
      <md>
        <mrow>[T]_{\basis{C} \leftarrow \basis{B}} [T^{-1}]_{\basis{B} \leftarrow \basis{C}} \amp = [T \circ T^{-1}]_{\basis{C} \leftarrow \basis{C}} \amp \amp  (<xref ref="functoriality_of_matrix"/>)</mrow>
        <mrow>\amp = [\id_W]_{\basis{C} \leftarrow \basis{C}} \amp \amp  (T \circ T^{-1} = \id_W)</mrow>
        <mrow>\amp = I</mrow>
      </md>
      and
      <md>
        <mrow>[T^{-1}]_{\basis{B} \leftarrow \basis{C}} [T]_{\basis{C} \leftarrow \basis{B}} \amp = [T^{-1} \circ T]_{\basis{B} \leftarrow \basis{B}} \amp \amp  (<xref ref="functoriality_of_matrix"/>)</mrow>
        <mrow>\amp = [\id_V]_{\basis{B} \leftarrow \basis{B}} \amp \amp (T^{-1} \circ T = \id_V)</mrow>
        <mrow>\amp = I</mrow>
      </md>.
    </p>
  </proof>

  <p>
    The next Lemma says that the change-of-basis matrix from <xref ref="Ch2Sec5ChangeOfBasis">Section</xref>
    is just the matrix of the identity linear map with respect to the relevant bases.
  </p>

  <lemma xml:id="change-of-basis-as-matrix">
    <statement>
      <p>
        Let <m>\basis{B}</m> and <m>\basis{C}</m> be bases for an <m>m</m>-dimensional vector space <m>V</m>.
        Then
        <me>
          \mat{P}_{\basis{C} \leftarrow \basis{B}} = [\id]_{\basis{C} \leftarrow \basis{B}}
        </me>.
      </p>
    </statement>

  <proof>
    <p>
      <md>
        <mrow>\mat{P}_{\basis{C} \leftarrow \basis{B}} \amp = \left[ [\ve{b}_1]_{\basis{C}} \cdots [\ve{b}_m]_{\basis{C}} \right] \amp \amp  \text{(Defn of } \mat{P}_{\basis{C} \leftarrow \basis{B}})</mrow>
        <mrow>\amp = \left[ [\id(\ve{b}_1)]_{\basis{C}} \cdots [\id(\ve{b}_m)]_{\basis{C}} \right]</mrow>
        <mrow>\amp = [\id]_{\basis{C} \leftarrow \basis{B}}. \amp \amp  \text{(Defn of } [\id]_{\basis{C} \leftarrow \basis{B}})</mrow>
      </md>
    </p>
  </proof>
</lemma>

  <p>
    The next Theorem tells us how the matrix of a linear operator changes when we change the basis used in computing it.
  </p>

  <theorem xml:id="matrix-in-different-basis">
    <statement>
      <p>
        Let <m>\basis{B}</m> and <m>\basis{C}</m> be bases for a vector space <m>V</m>,
        and let <m>T : V \rightarrow V</m> be a linear operator on <m>V</m>.
        Then
        <me>
          [T]_{\basis{C} \leftarrow \basis{C}} = \mat{P}^{-1} [T]_{\basis{B} \leftarrow \basis{B}} P
        </me>
        where <m>P \equiv P_{\basis{B} \leftarrow \basis{C}}</m>.
      </p>
    </statement>
    <proof>
      <p>
        <md>
          <mrow>\text{RHS}  \amp = \mat{P}^{-1} [T]_{\basis{B} \leftarrow \basis{B}} P</mrow>
          <mrow>\amp = [\id]_{\basis{B} \leftarrow \basis{C}}^{-1} [T]_{\basis{B} \leftarrow \basis{B}} [\id]_{\basis{B} \leftarrow \basis{C}} \amp \amp  (<xref ref="change-of-basis-as-matrix"/>)</mrow>
          <mrow>\amp = [\id]_{\basis{C} \leftarrow \basis{B}} [T]_{\basis{B} \leftarrow \basis{B}} [\id]_{\basis{B} \leftarrow \basis{C}} \amp \amp  (<xref ref="inverse-of-map-via-matrices"/>)</mrow>
          <mrow>\amp = [ \id \circ T \circ \id]_{\basis{C} \leftarrow \basis{C}} \amp \amp  (<xref ref="functoriality_of_matrix"/>)</mrow>
          <mrow>\amp = [T]_{\basis{C} \leftarrow \basis{C}}</mrow>
          <mrow>\amp = \text{LHS} </mrow>
        </md>.
      </p>
    </proof>
  </theorem>

  <exercises>
    <exercisegroup>
      <introduction>
        <p>
          Compute the matrices associated to the following linear maps:
        </p>
      </introduction>
    <exercise>
      <statement>
        <p>
          Let <m>T:\Row_3\to \Row_2</m> be the linear map defined by <m>T(x,y,z) = (2x+y,x-y-z)</m>.
          Let <m>\basis{B}</m> and <m>\basis{B}'</m> be the standard bases for <m>Row_3</m> and <m>Row_2</m>.
          Calculate the matrix
          <me> [T]_{\basis{B}'\leftarrow \basis{B}} </me>
        </p>
      </statement>
      <answer>
        <p>
          <m>[T]_{\basis{B}'\leftarrow \basis{B}} = \begin{bmatrix}  2 \amp 1 \amp 0 \\ 1\amp  -1\amp -1 \end{bmatrix}  </m>
        </p>
      </answer>
    </exercise>
    <exercise>
      <statement>
        <p>
          Let <m>T</m> be the same map as in (a),
          but now use the bases
          <m>\basis{B}=\bopen (2,1,0),(1,2,1), (3,2,1)\bclose</m> and
          <m>\basis{B}'=\bopen(1,1),(1,0)\bclose</m>.
          Calculate the matrix
          <me> [T]_{\basis{B}'\leftarrow \basis{B}} </me>.
        </p>
      </statement>
      <answer>
        <p>
          <m> [T]_{\basis{B}'\leftarrow \basis{B}} = \begin{bmatrix} 1 \amp -4 \amp 0 \\ 4 \amp 8 \amp 8 \end{bmatrix} </m>
        </p>
      </answer>
      <solution>
        <p>
          Now <m>T((2,1,0)) = (5,1)</m>, <m>T((1,2,3)) = (4, -4)</m> and <m>T((3,2,1)) = (8,0)</m>.
          We need to write each of these as a linear combination of <m>(1,1)</m> and <m>(1,0)</m>.
          We have <m>(5,1) = 1(1,1)+4(1,0)</m>, and <m>(4,-4) = -4(1,1) + 8(1,0)</m> and <m>(8,0) = 0(1,1)+8(1,0)</m>. Thus
          <me> [T]_{\basis{B}'\leftarrow \basis{B}} = \begin{bmatrix} 1 \amp -4 \amp 0 \\ 4 \amp 8 \amp 8 \end{bmatrix} </me>
        </p>
      </solution>
    </exercise>
    <exercise>
      <statement>
        <p>
          Let <m>T:\Poly_2\to \Poly_1</m> be the 0 map,
          i.e. the linear map that maps all vectors in
          <m>\Poly_2</m> to the zero vector in <m>\Poly_1</m>.
          Use the standard bases on both sides to find
          <me> [T]_{\basis{B}'\leftarrow \basis{B}}</me>.
          Will the answer change if you used different bases?
        </p>
      </statement>
      <answer>
        <p>
          <m>[T]_{\mathcal{B}'\leftarrow \mathcal{B}} = \begin{bmatrix} 0 \amp 0 \amp 0 \\ 0 \amp 0 \amp 0 \end{bmatrix} </m>
        </p>
      </answer>
      <solution>
        <p>
          It doesn't matter which bases were chosen;
          the matrix would always look like this.
          If the vector spaces had different dimensions,
          then the associated matrix would have a different size,
          but the 0 map would still have associated matrix the zero matrix.
        </p>
      </solution>
    </exercise>

  <exercise xml:id="trig_ex_1">
    <statement>
      <p>
        Let
        <me>
          T : \Trig_1 \rightarrow \Trig_2
        </me>
        be the <q>multiply with <m>\sin x</m></q> linear map,
        <m>T(f)(x) = \sin x f(x)</m>.
        Compute <m>[T]_{\basis{C} \leftarrow \basis{B}}</m> with respect to the standard basis
        <m>\basis{B}</m> of <m>\Trig_1</m> and <m>\basis{C}</m> of <m>\Trig_2</m>.
      </p>
    </statement>
    <solution>
      <p>
        Recall the standard double angle formulae:
        <md>
          <mrow>\sin(2x) \amp = 2 \sin x \cos x</mrow>
          <mrow> \cos(2x) \amp = \cos^2 x - \sin^2 x = 2\cos^2 x - 1 = 1-2\sin^2 x</mrow>
        </md>.
        With these in mind, we compute:
        <md>
          <mrow>T(T_0) \amp= \sin x = T_2 </mrow>
          <mrow>T(T_1) \amp = \sin x \cos x = \frac{1}{2}\sin(2x) = \frac{1}{2}T_4 </mrow>
          <mrow> T(T_2) \amp = \sin x \sin x = \frac{1}{2} - \frac{1}{2}\cos(2x) = \frac{1}{2}T_0 - \frac{1}{2}T_3 </mrow>
        </md>.
        Thus
        <me>
          [T]_{\basis{C} \leftarrow \basis{B}}= \begin{bmatrix} 0 \mamp 0 \mamp \frac{1}{2} \\ 0 \mamp 0 \mamp 0 \\ 1 \mamp 0 \mamp 0 \\ 0 \mamp 0 \mamp -\frac{1}{2}\\ 0 \mamp \frac{1}{2} \mamp 0 \end{bmatrix}.
        </me>
      </p>
    </solution>
  </exercise>

  <exercise xml:id="trig_ex_2">
    <statement>
      <p>
        Let
        <me>
          S : \Trig_2 \rightarrow \Trig_2
        </me>
        be the <q>shift by <m>\frac{\pi}{6}</m></q> map,
        <m>S(f)(x) = f(x - \frac{\pi}{6})</m>.
        <ol label="(a)">
          <li>
            Compute <m>[S]_{\basis{C} \leftarrow \basis{C}}</m> with respect to the standard basis <m>\basis{C}</m> of <m>\Trig_2</m>.
          </li>
          <li>
            Compute <m>[S]_{\basis{B} \leftarrow \basis{C}}</m>, where <m>\basis{B}</m> is the following basis for <m>\Trig_2</m>:
            <me>
              \basis{B} = \bopen 1, \cos x, \sin x, \cos^2 x, \sin^2 x \bclose
            </me>
          </li>
        </ol>
      </p>
    </statement>
    <solution>
      <p>
        In this exercise, we shall use the standard composite angle formulae for trigonometric functions:
        <md>
          <mrow>\cos(x - y) \amp = \cos x \cos y + \sin x \sin y </mrow>
          <mrow>\sin(x-y) \amp = \sin x \cos y - \cos x \sin y </mrow>
        </md>.
        We compute
        <md>
          <mrow> S(T_0) \amp = 1 = T_0 </mrow>

          <mrow> S(T_1) \amp = \cos ( x - \frac{\pi}{6}) =  \frac{\sqrt{3}}{2} \cos x + \frac{1}{2}\sin x = \frac{\sqrt 3}{2} T_1 + \frac{1}{2} T_2</mrow>

          <mrow> S(T_2) \amp = \sin( x - \frac{\pi}{6}) =  -\frac{1}{2} \cos x +  \frac{\sqrt 3}{2}\sin x =  -\frac{1}{2}T_1 + \frac{\sqrt 3}{2} T_2 </mrow>

          <mrow> S(T_3) \amp = \cos(2x - \frac{\pi}{6})=  -\frac{1}{2}\sin^2 x  + \frac{\sqrt 3}{2}\cos^2 x + \sin x \cos x</mrow>

          <mrow> \amp  = -\frac{\sqrt 3}{2}(\frac{1}{2} - \frac{1}{2}\cos x) + \frac{\sqrt 3}{2}(\frac{1}{2} + \frac{1}{2}\cos 2x) + \frac{1}{2}\sin 2x </mrow>

          <mrow> \amp = \frac{\sqrt 3}{2}\cos 2x + \frac{1}{2} \sin 2x = \frac{\sqrt 3}{2} T_3 + \frac{1}{2} \sin 2x .</mrow>
        </md>
        Similarly,
        <md>
          <mrow> S(T_4) = \sin (2x - \frac{\pi}{6}) =  -\frac{1}{2} \cos 2x + \frac{\sqrt 3}{2} \sin 2x = -\frac{1}{2} T_3 + \frac{\sqrt 3}{2}T_4.</mrow>
        </md>
        Hence
        <me>
          [S]_{\basis{C} \leftarrow \basis{C}} = \begin{bmatrix}
          1  \mamp 0 \mamp 0 \mamp 0 \mamp 0 \\

          0 \mamp \frac{\sqrt 3}{2} \mamp -\frac{1}{2} \mamp 0 \mamp 0 \\

          0 \mamp \frac{1}{2} \mamp \frac{\sqrt 3}{2} \mamp 0 \mamp 0 \\

          0 \mamp 0 \mamp 0 \mamp \frac{\sqrt 3}{2} \mamp -\frac{1}{2} \\

          0 \mamp 0 \mamp 0  \mamp \frac{1}{2} \mamp \frac{\sqrt 3}{2}
          \end{bmatrix}.
        </me>
      </p>
    </solution>
  </exercise>
</exercisegroup>

<exercisegroup>
  <introduction>
    <p>
      Given the associated matrix, write down how the
      linear map acts on a general element of the vector
      space.
    </p>
  </introduction>
  <exercise>
    <statement>
      <p>
        Let <m>T:\Row_3\to \Row_4</m> with the standard bases on both sides. Suppose that its associated matrix is
        <me> \begin{bmatrix} 1\amp 2\amp 3\\1\amp 0\amp 1\\ 2\amp 1\amp 1\\ -1\amp -2\amp 2 \end{bmatrix} </me>.
        Write down the value of <m>T(x,y,z)</m>.
      </p>
    </statement>
    <answer>
      <p>
        <m>T(x,y,z) = (x+2y+3z, x+z, 2x+y+z, -x-2y+2z)</m>
      </p>
    </answer>
  </exercise>

  <exercise>
    <statement>
      <p>
        Let <m>T:\Row_2\to \Row_3</m> with bases <m>(1,1),(1,-1)</m> and <m>(1,0,1), (1,-1,0), (0,1,1)</m> with associated matrix
        <me> \begin{bmatrix} 1\amp -1\\0\amp 1\\1\amp 0 \end{bmatrix} </me>
        Write down the value of <m>T(x,y)</m>.
      </p>
    </statement>
  <solution>
    <p>
      The given information means that
      <m>T(1,1) = 1(1,0,1)+0(1,-1,0)+1(0,1,1)=(1,1,2)</m>
      and <m>T(1,-1)=-1(1,0,1)+1(1,-1,0)+0(0,1,1) = (0,-1,-1)</m>.
      Thus <m>T(1,0)=\frac{1}{2}(T(1,1)+T(1,-1))=\frac{1}{2}(1,0,1) = \left(\frac{1}{2},0,\frac{1}{2}\right)</m>
      and <m>T(0,1) = T(1,1)-T(1,0)=\left(\frac{1}{2},1,\frac{3}{2}\right)</m>
      and thus
      <me> T(x,y) = xT(1,0)+yT(0,1) = \left( \frac{x+y}{2},y,\frac{x+3y}{2} \right)</me>.
    </p>
  </solution>
  </exercise>
</exercisegroup>

  <exercise>
    <statement>
      <p>
        Verify <xref ref="lin-map-in-matrix-theorem">Theorem</xref>
        for the linear map <m>S : \Mat_{2,2} \rightarrow \Mat_{2,2}</m> given by <m>S(\mat{M}) = \mat{M}^T</m>,
        for the vector <m>\mat{A} \in \Mat_{2,2}</m> given by
        <md>
          <mrow> \mat{A} = \begin{bmatrix} 0 \mamp  1 \\ 0 \mamp  0 \end{bmatrix}</mrow>
        </md>
        and using the following bases of <m>\Mat_{2,2}</m>:
        <me>
          \basis{B} = \basis{C} = \bopen \mat{M}_1 = \begin{bmatrix}1 \mamp  1 \\ 2 \mamp  3\end{bmatrix}, \, \mat{M}_2 = \begin{bmatrix}1 \amp  0 \\ 1 \amp  1 \end{bmatrix}, \, \mat{M}_3 = \begin{bmatrix}1 \amp  1 \\ 1 \amp  1\end{bmatrix}, \, \mat{M}_4 =\begin{bmatrix}0 \amp  1 \\ 1 \amp  1 \end{bmatrix} \bclose.
        </me>
      </p>
    </statement>
    <hint>
      <p>
        You need to compute <m>[\mat{A}]_{\basis B}</m>, <m>[S]_{\basis C\leftarrow \basis B}</m> and <m>[S(\mat{A})]_{\basis C}</m>  and verify that
        <me> [S(\mat{A})]_{\basis C} = [S]_{\basis C\leftarrow\basis B}[\mat{A}]_{\basis B}</me>.
      </p>
    </hint>
    <answer>
      <p>
        <md>
          <mrow> S(\mat{A}) \amp = \begin{bmatrix} 0 \amp 0\\ 1\amp 0\end{bmatrix}</mrow>
          <mrow> [\mat{A}]_{\basis B} \amp = \begin{bmatrix} 0\\ -1\\ 1\\ 0\end{bmatrix} </mrow>
          <mrow> [S(\mat{A}]_{\basis C} \amp = \begin{bmatrix} -1\\ 2\\-1\\ 2 \end{bmatrix} </mrow>
          <mrow> [S]_{\basis C\leftarrow \basis B} \amp = \begin{bmatrix}
            2  \amp 1  \amp 0 \amp 0\\
            -3 \amp -2 \amp 0 \amp 0\\
            2  \amp 2  \amp 1 \amp 0\\
            -2 \amp -2 \amp 0 \amp 1
          \end{bmatrix}</mrow>
        </md>.
      </p>
    </answer>
    <solution>
      <p>
        The easiest to compute is <m>S(\mat{A}) = \mat{A}^T = \begin{bmatrix} 0\amp 0\\1\amp 0\end{bmatrix}</m>.
      </p>
      <p>
        Now we can compute <m>[\mat{A}]_{\basis B}</m>.
        Set
        <me>[\mat{A}]_{\basis B} = \begin{bmatrix} a\\b\\c\\d\end{bmatrix}</me>.
        This means that
        <me>\mat{A} = a \mat{M}_1 + b\mat{M}_2 +c\mat{M}_3 +d \mat{M}_4</me>.
        If we now compare each of the four entries on the left and right hand-sides, we get the system
        <md>
          <mrow> 0 \amp = a + b + c </mrow>
          <mrow> 1 \amp = a + c + d</mrow>
          <mrow> 0 \amp = 2a + b + c + d</mrow>
          <mrow> 0 \amp = 3a + b + c + d</mrow>
        </md>.
        It has the solution <m>a=0, b=-1, c=1, d=0</m> and thus
        <me> [\mat{A}]_{\basis B} = \begin{bmatrix} 0\\-1\\1\\0\end{bmatrix}</me>.
        We do the same with <m>S(\mat{A})</m> to get that
        <me> [S\mat{A}]_{\basis C} = \begin{bmatrix} -1\\2\\-1\\2 \end{bmatrix}</me>.
      </p>
      <p>
        To get the matrix for <m>S</m>,we have to apply the map <m>S</m> to each of the basis elements <m>\mat{M}_1, \mat{M}_2, \mat{M}_3, \mat{M}_4</m> and then write the answer as a linear combination os those same basis elements (because <m>\basis B = \basis C</m>).
        That linear combination describes the coordinate vectors
        <me>[S(\mat{M}_1)]_{\basis C}, [S(\mat{M}_2)]_{\basis C}, [S(\mat{M}_3)]_{\basis C}, [S(\mat{M}_4)]_{\basis C}</me>
        that form the columns of <m>[S]_{\basis C\leftarrow\basis B}</m>. We get
        <me>[S]_{\basis C\leftarrow\basis B}=\begin{bmatrix}
            2  \amp 1  \amp 0 \amp 0\\
            -3 \amp -2 \amp 0 \amp 0\\
            2  \amp 2  \amp 1 \amp 0\\
            -2 \amp -2 \amp 0 \amp 1
          \end{bmatrix}</me>.
          Lastly, we check that the product
          <me>\begin{bmatrix}
            2  \amp 1  \amp 0 \amp 0\\
            -3 \amp -2 \amp 0 \amp 0\\
            2  \amp 2  \amp 1 \amp 0\\
            -2 \amp -2 \amp 0 \amp 1
          \end{bmatrix}\begin{bmatrix} 0\\ -1\\ 1\\ 0\end{bmatrix}
        </me>
        equals
        <me>\begin{bmatrix} -1\\ 2\\-1\\ 2 \end{bmatrix}</me>,
        which is indeed the case.
      </p>
    </solution>
  </exercise>

  <exercise>
    <statement>
      <p>
        Verify <xref ref="lin-map-in-matrix-theorem"/> for the linear map
        <me>
          T : \Poly_3 \rightarrow \Trig_3
        </me>
        defined by
        <me>
          T(p)(x) := p(\cos x).
        </me>
        Use the standard bases <m>\basis{B}</m> for <m>\Poly_3</m> and <m>\basis{C}</m> for <m>\Trig_3</m>.
      </p>
    </statement>
  </exercise>

  <exercise>
    <statement>
      <p>
        Check that the linear maps <m>T</m> and <m>S</m> from <xref ref="trig_ex_1">Exercises</xref>
        and <xref ref="trig_ex_2"></xref>
        satisfy <m>[S \circ T]_{\basis{C} \leftarrow \basis{B}} = [S]_{\basis{B} \leftarrow \basis{B}} [T]_{\basis{C} \leftarrow \basis{B}}</m>.
      </p>
    </statement>
  </exercise>

  <exercise>
    <statement>
      <p>
        Let <m> \basis{B} = \bopen e^x, xe^x, x^2e^x, x^3e^x\bclose </m>
        be a basis for a vector space <m>V</m> of functions.
        Compute the matrix associated to differentiation
        <m> D:V\to V </m> with respect to this basis.
        Find its inverse and use it to compute an
        anti-derivative of <m> (x^3-x^2)e^x </m>.
      </p>
    </statement>
    <solution>
      <p>
        We have <m>D(e^x) = e^x</m> and <m>D(xe^x) = xe^x + e^x</m> and <m>D(x^2e^x) = 2xe^x + x^2e^x</m> and <m>D(x^3e^x) = x^3e^x + 3x^2 e^x</m>. Thus the matrix associated with <m>D</m> is
        <me>[D]_{\mathcal{B}} = \begin{bmatrix} 1\amp 1\amp 0\amp 0 \\ 0\amp 1\amp 2\amp 0 \\ 0\amp 0\amp 1\amp 3 \\ 0\amp 0\amp 0\amp 1 \end{bmatrix} </me>.
        Its inverse is <m>\begin{bmatrix} 1\amp -1\amp 2\amp -6 \\ 0\amp 1\amp -2\amp 6\\ 0\amp 0\amp 1\amp -3 \\ 0\amp 0\amp 0\amp 1 \end{bmatrix}</m>.
        Thus, an anti-derivative of <m>(x^3-x^2)e^x</m> has a coordinate vector
        <me> \begin{bmatrix} 1\amp -1\amp 2\amp -6 \\ 0\amp 1\amp -2\amp 6\\ 0\amp 0\amp 1\amp -3 \\ 0\amp 0\amp 0\amp 1 \end{bmatrix} \begin{bmatrix} 0\\0\\-1\\1 \end{bmatrix} = \begin{bmatrix} -8\\8\\-4\\ 1 \end{bmatrix}</me>.
        So, <m>\int (x^3-x^2)e^x dx = -8e^x+8xe^x-4x^2e^x+x^3e^x + C</m>.
      </p>
    </solution>
  </exercise>

  <exercise>
    <statement>
      <p>
        Verify <xref ref="functoriality_of_matrix"/> for the <q>gradient</q> and <q>divergence</q> linear maps
        <md>
         <mrow> G : \Poly_3[x,y] \amp \rightarrow \Vect_2(\mathbb{R}^2) </mrow>
         <mrow> G(p) := \nabla p</mrow>
         <mrow>\Div : \Vect_2(\mathbb{R}^2) \amp \rightarrow \Poly_1[x,y]</mrow>
         <mrow> \Div( (P, Q) ) \amp := \frac{\partial P}{\partial x} + \frac{\partial Q}{\partial y}</mrow>
        </md>
        Use the standard bases
        <me>
          \basis{B} = \bopen 1, x, y, x^2, xy, y^2, x^3, x^2y, xy^2, y^3 \bclose
        </me>
        <md>
          <mrow>
          \basis{C} = \bopen (1, 0), (x, 0), (y, 0), (x^2, 0), (xy, 0), (y^2, 0), </mrow>
          <mrow>(0, 1), (0, x), (0, y), (0, x^2), (0, xy), (0, y^2) \bclose </mrow>
        </md>
        <me>
          \basis{D} = \bopen 1, x, y \bclose
        </me>
        for <m>\Poly_3[x,y]</m>, <m>\Vect_2(\mathbb{R}^2)</m>, <m>\Poly_1[x,y]</m> respectively. That is, compute
        <me>
          [\Div]_{\basis{D} \leftarrow \basis{C}} [G]_{\basis{C} \leftarrow \basis{B}}
        </me>
        and
        <me>
          [\Div \circ G]_{\basis{D} \leftarrow \basis{C}}
        </me>
        and check that they are equal.
      </p>
    </statement>
  </exercise>

  <exercise>
    <statement>
      <p>
        Verify <xref ref="functoriality_of_matrix"/> in the case of the linear maps
        <md>
          <mrow> S : \Mat_{2,3} \amp \rightarrow \Col_3</mrow>
          <mrow> \begin{bmatrix} A_{11} \amp A_{12} \amp A_{13} \\ A_{21} \amp A_{22} \amp A_{23} \end{bmatrix} \amp \mapsto \begin{bmatrix} A_{11} + A_{21} \\ A_{12} + A_{22} \\ A_{13} + A_{23} \end{bmatrix} </mrow>
        </md>
        <md>
          <mrow> T : \Col_3 \amp \rightarrow \Poly_2[x,y]</mrow>
          <mrow>\begin{bmatrix} a \\ b \\ c \end{bmatrix} \amp \mapsto a + b(x-y-1)^2 + c(x+y+1)^2</mrow>
        </md>
        Use the standard basis <m>\basis{B}</m> for <m>\Mat_{2,3}</m> (see <xref ref="dimension_of_matrix_space_example"/>), the basis
        <me>
          \basis{C} = \bopen \begin{bmatrix} 1 \\ 0 \\ 1\end{bmatrix}, \begin{bmatrix} 0 \\ 1 \\ 0\end{bmatrix}, \begin{bmatrix} 0 \\ 1 \\ 1\end{bmatrix} \bclose
        </me>
        for <m>\Col_3</m>, and the standard basis
        <me>
          \basis{C} = \bopen 1, x, y, x^2, xy, y^2 \bclose
        </me>
        for <m>\Poly_2[x,y]</m>. That is, compute
        <me>
          [T \circ S]_{\basis{D} \leftarrow \basis{B}}
        </me>
        and
        <me>
          [T]_{\basis{D} \leftarrow \basis{C}} [S]_{\basis{C} \leftarrow \basis{B}}
        </me>
        and check that they are equal.
      </p>
    </statement>
  </exercise>

  <exercise>
    <statement>
      <p>
        Consider the linear map <m>T(x,y)=(x+y,2x)</m>.
        Show that <m>(T((1,1)) = 2(1,1)</m> and that <m> T((-1,2)) = (-1)\cdot(-1,2)</m>.
        Compare the two matrices associated to <m>T</m> <mdash />
        the one associated to the standard basis,
        and the one associated to the basis <m>((1,1),(-1,2))</m>.
      </p>
      <p>
        This is another reason why we sometimes want to use different bases. Sometimes we are really interested in the linear map and a different choice of basis makes the linear map appear <q>better</q> and therefore easier to study.
      </p>
    </statement>
    <solution>
      <p>
        With respect to the standard basis we have
        <me> [T]_{\mathcal{B}} = \begin{bmatrix} 1 \amp  1 \\ 2 \amp  0 \end{bmatrix} </me>
        and with respect to the new basis we have
        <me> [T]_{\mathcal{B}'} = \begin{bmatrix} 2\amp 0 \\ 0\amp -1 \end{bmatrix} </me>
      </p>
      <p>
        In this example, the second matrix does not look that much simpler than the first.
        But for larger matrices, there is a big advantage in getting a matrix in diagonal form.
        It makes it much easier to compute powers of this matrix, the determinant, and many other things.
      </p>
    </solution>
  </exercise>

  <exercisegroup>
    <title> Proof type problems</title>
    <exercise>
      <statement>
        <p>
          Let <m>I : V\to V</m> be the identity map on <m>V</m>.
          Prove that the matrix associated to <m>I</m> with respect to the bases <m>\basis{B}</m> and <m>\basis{B}'</m> is the change of basis matrix, i.e. prove that
          <me>
            [I]_{\basis{B}'\leftarrow \basis{B}} = \mat{P}_{\basis{B}'\leftarrow \basis{B}}
          </me>.
        </p>
      </statement>
      <hint>
        <p>
          The identity map satisfies <m>I(v) = v</m> for all <m>v\in V</m>. Now use that formula to relate the definitions of <m>[I]_{\basis{B}'\leftarrow \basis{B}}</m> (<xref ref="matrix_of_linear_map_defn" />) and of <m>\mat{P}_{\basis{B}'\leftarrow \basis{B}}</m> (<xref ref="def-change-of-basis-matrix" />).
        </p>
      </hint>
      <solution>
        <p>
          Let <m>\basis{B} = (b_1,\ldots, b_n)</m>. Then the change of basis matrix is
          <me>
            \left[[b_1]_{\basis{B}'} \mid \cdots \mid [b_n]_{\basis{B}'}\right]
          </me>
          while the matrix associated to the linear map <m>I</m> is
          <me> \left[[I(b_1)]_{\basis{B}'} \mid \cdots \mid [I(b_n)]_{\basis{B}'}\right]</me>.
          But since <m>I</m> is the identity map,
          we have <m>I(v)=v</m> for all <m>v\in V</m>
          and in particular <m>I(b_i)=b_i</m> for each <m>i</m>.
          Thus, the two matrices are defined by the same formula, proving the statement.
        </p>
      </solution>
    </exercise>

    <exercise>
      <statement>
        <p>
          Let <m>I:V\to V</m> be the identity map on <m>V</m>.
          Prove that no matter what basis <m>\basis{B}</m> we choose,
          the associated matrix <m> [I]_{\basis{B}\leftarrow\basis{B}}</m> is always the identity matrix.
          (What is the difference between this and the previous problem?)
        </p>
      </statement>
      <solution>
        <p>
          This can be done with a direct computation. If <m>\basis{B} = (b_1,\ldots, b_n)</m>, then we have
          <me>
            [I]_{\basis{B}\leftarrow \basis{B}} =  \left[[I(b_1)]_{\basis{B}'} \mid \cdots \mid [I(b_n)]_{\basis{B}'}\right]
          </me>
          Each <m>I(b_i)=b_i</m> and since
          <m>b_i=0\cdot b_1 + \cdots + 0\cdot b_{i-1}+1\cdot b_i+0\cdot b_{i+1}+\cdots+0\cdot b_n</m>,
          the coordinate vector consists of all zeros, except a 1 in the <m>i</m>-th position.
          If you place these <m>n</m> column vectors next to each other,
          you get exactly the identity matrix.
        </p>
      </solution>
    </exercise>

<!--
  This is already Theorem 3.4.9 Functoriality ..., but I am keeping it in case we need a different approach
    <exercise>
      <statement>
        <p>
          If <m>T: U \to V</m> and <m>S:V\to W</m> are two linear maps, and <m>\mathcal{B}</m>, <m>\basis{B}'</m> and <m>\basis{B}''</m> are bases for <m>U</m>, <m>V</m> and <m>W</m>, respectively, then
          <me>
            [S\circ T]_{\basis{B}''\leftarrow \basis{B}} = [S]_{\basis{B}''\leftarrow \basis{B}'}[T]_{\basis{B}'\leftarrow \basis{B}}
          </me>.
        </p>
      </statement>
      <solution>
        <p>
          If we can show that for all vectors <m>u\in U</m> we have
          <me> [S\circ T]_{\basis{B}''\leftarrow\basis{B}} [u]_{\basis{B}} = [S]_{\basis{B}''\leftarrow\basis{B}'}[T]_{\basis{B}'\leftarrow \basis{B}} [u]_{\basis{B}} </me>
          then we can do the same trick as when we proved
          that two change of basis matrices were equal.
          By setting the vector <m>u</m> equal to the
          basis elements in <m>\basis{B}</m> one by one,
          their coordinate vectors range through the
          standard basis elements for <m>\Col_n</m>.
          And by multiplying these matrices
          (the one on the left and the product on the right)
          by the <m>i</m>-th standard basis element of
          <m>\Col_n</m> we isolate the <m>i</m>-th column
          of each matrix. If they are always equal, each
          corresponding column of the matrices are equal,
          and thus we will have proved what we wanted to.
        </p>
        <p>
          We now show the equation in the second line.
          On the left hand side we have
          <me>
            [S\circ T]_{\basis{B}''\leftarrow\basis{B}} [u]_{\basis{B}} = [(S\circ T)(u)]_{\basis{B}''}
          </me>,
          while on the right hand side we have
          <me>
            [S]_{\basis{B}''\leftarrow\basis{B}'}[T]_{\basis{B}'\leftarrow \basis{B}} [u]_{\basis{B}} = [S]_{\basis{B}''\leftarrow\basis{B}'}[T(u)]_{\basis{B}'} = [S(T(u))]_{\basis{B}''}
          </me>
          These two vectors are the same, and the proof is complete.
        </p>
      </solution>
    </exercise>
  -->
  </exercisegroup>

</exercises>

<solutions inline="statement answer solution">
  <title> Answers and solutions to Checkpoints in this section</title>
</solutions>

</section>

